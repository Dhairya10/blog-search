{"id": "47804f40-25f6-4c21-ba97-f5810bb56c19", "author": "Jason Fried", "title": "Achieving optionality", "content": "It took me a while to fully realize the value of something my company achieved years ago, and continues to savor today. It’s one of our greatest quiet advantages, full stop. It’s not something you hear much about in business circles. In fact, I can’t remember the last time I heard anyone spend much time on the topic, or even bring it up in conversation, on a conference stage, or behind a podcast mic. There is, however, lots of discussion about achievement in business. A company can achieve product market fit, operational efficiency, influence, revenue goals, or, ultimately — and hopefully — profitability. But I’m not taking about those things. Those are the obvious things, the common talking points. And to those you can add the vanity metrics of achievement — social media followers, traffic, views, impressions, open rates, press mentions, gross this or gross that. All those are what they are, but they aren’t where it’s at. What I’m talking about is optionality. Achieving optionality is where it’s at. Optionality is a hearty mix of profit margin, small size, independence, attitude, and freedom. You’ve got to have all of it to have optionality. If a board is calling the shots, you don’t have much optionality. If your margins are thin, or non-existent, you don’t have much optionality. If the public owns a piece, you don’t have much optionality. If you rely on investment to pay the bills, you don't have much optionality. If you’re too big to change direction quickly, you don’t have much optionality. And if you’re afraid to speak your mind and stake your point of view, you don’t have much optionality. Optionality lets you do things no one would give you permission to do. It lets you write excellent software and give it away for free if you choose. It lets you do things that don’t make sense in the current climate, but will long-term. It lets you be early while eventually catches up. Optionality is ecstasy. It’s making it up as you go, without making excuses. It’s openly changing your mind without having to save face. Optionality is equanimity, the corporate equivalent of enlightenment. So, entrepreneurs, ditch the bullshit. Abandon growth-at-all-costs. Reject conventional metrics. Scorn hollow acceptance. Instead, hunt for optionality. It's freedom. It's power. It's everything you crave, wrapped in a single, potent package. Chase it relentlessly. And when you get it, don’t let go. -Jason", "date": "2024-07-12T21:55:00Z", "url": "https://world.hey.com/jason/achieving-optionality-56634dd3"}
{"id": "a6cf66f8-bc7c-4069-a049-a25acdb9b531", "author": "Jason Fried", "title": "Directional decisions", "content": "In the course of building products, you’ll make a thousand common decisions, but only a handful of directional decisions. While a common decision may alter a specific feature, design, or implementation, a directional decision remaps the fundamental trajectory of the entire product. Make a directional decision and you’re now pointed this way or that way. Make a directional decision and you either shut something off or open something up. Make a directional decision and you’ll get a hundred no’s for the price of one. Let’s look at a specific directional decision we made for Writebook , our latest product. Writebook is remarkably simple software that lets you publish text and pictures in a simple, browsable online book format. Books are written and published. This presents an opportunity to make a directional decision: Is Writebook a writing tool or a publishing tool? Or both? At one point, we treated the publishing side and the writing side as equals. Both are involved in getting a book online. Seems reasonable, right? Reasonable isn’t the measure, though. It’s easy to say something should do everything well because saying something is easy doesn’t involve any work, or require any tradeoffs. But building products is all about tradeoffs. When there are no tradeoffs in the conversation you’re having, you know you aren’t building, you’re just talking. But it was time to build. But what’s the epicenter of Writebook? What’s the thing you can do easily with Writebook that was a lot harder without Writebook? Essentially, what does Writebook exist to do? What did the current world look like without Writebook? You can write books in a thousand tools in a thousand places. But instantly publishing a book in a simple web-friendly format is really hard. It generally involves a lot of custom work, or a complex CMS system, or bending some blogging platform into a pretzel just to unsatisfyingly make it sorta kinda create books instead of blogs. And since Writebook supports Markdown, you can easily write in a simple text editor and then copy and paste the finished text into Writebook when you’re ready. The place to write isn’t what’s lacking out there. The place to publish is. So we made a directional decision: Writebook was a publishing tool. You could obviously still write in it — we even designed a new Markdown editor to make basic formatting easier. But, our overall directional deciding Writebook was about publishing rather than writing allowed us to say no to dozens of days of additional work and sidestep piles of additional complexity. But how did that decision come to be? Why did it happen? When did it happen? Well, before we settled on the publishing angle, we went down the “writing and publishing are equals” path. Part of that project involved building a system to track diffs so an author (or multiple) could track changes, additions, and subtractions. Writing software usually has this sort of thing, so if we were making writing software it felt like basic table stakes. It was during a design review that it hit me. This is fucking complicated and unnecessary. It’ll work, but it’s not actually useful. And, further, trying to build a multiple-author change tracking system to our standards is going to distract us from the more important, core differentiation work we have to do on the publishing side. So I wrote up my thoughts and posted it to the Writebook project in Basecamp. Here is that post in full: https://public.3.basecamp.com/p/4SfGJ2wQNXdUArbxf7FjDouz I concluded with: Workbook is a final publishing platform, it's not a collaborative editing environment. What we're solving for is easily getting a book up online, in in various formats, in the simplest, quickest, more comprehensive way. If you want comprehensive collaborative editing and change tracking, write it elsewhere and, when it's done, pop it in here to publish. We ended up keeping a very minimal version of writing history in place as a backstop for major mistakes (“Oh shit, I deleted the whole thing by accident”), but in the final version of Writebook there’s no formal track changes feature, no colored diffs, and no focus on the collaborative writing process. Writebook is simply a final publishing platform first and foremost. You can write and edit in it, but it’s bare bones and basic — which is fine almost all of the time anyway. And guess what? Writebook has been out for a few weeks now and tracking changes or sophisticated collaborative editing tools or features has barely been requested. I’m glad we explored it early on, but even more glad we dropped it in the end. Publishing was the right direction. -Jason", "date": "2024-07-11T18:03:52Z", "url": "https://world.hey.com/jason/directional-decisions-22bcd41c"}
{"id": "876061b3-239f-4683-a9b0-8c02149918ab", "author": "Jason Fried", "title": "Introducing Writebook", "content": "You know, it's really easy to publish short form content on a variety of social platforms. And individual blog posts on a number of other platforms. These are solved problems. But it's surprisingly challenging to publish books on the web in nice, cohesive, tight, easy-to-navigate HTML format. A collection of 20 essays can be a book. Or a company's handbook can be a book. Or an actual book like Shape Up can be a book. But usually you have to make a custom web site, or stretch to use a blog publishing/CMS tool to kinda-sorta squish separate posts together into a packaged whole. It's really not ideal. We know — we've published a variety of books online, and we've had to go the custom route each time. Having to go the custom route for something that should be fundamentally simple is a red flag. And an opportunity. It really shouldn't be this hard. So we did something about it. Introducing Writebook. It's a dead simple platform to publish web-based books. They have covers, they can have title pages, they can have picture pages, and they can have text pages. Each book gets its own URL, and navigating and keeping track of your progress is all built right in. Writebook isn't a service — it's software you download and install on your own server. We've made it incredibly easy to get going — it just takes a few minutes. Even non-technical folks can get it all set up. We'll email you a single command you paste into a terminal and it takes care of the rest. No maintenance required either, it takes care of itself, auto-updates, etc. Writebook also comes with all the Rails code so you can see how it's built, modify it for your own use, and learn how applications like this are made. And how much for all this? Absolutely nothing. Writebook is FREE. Writebook is our love letter to truly independent, zero-cost web publishing on the open web. No gatekeepers, no publisher required. Just you and your words for the world. Learn more and get it here: http://once.com/writebook -Jason", "date": "2024-07-03T18:46:36Z", "url": "https://world.hey.com/jason/introducing-writebook-e217cae3"}
{"id": "a9e27f03-90c8-4296-880b-23698e4e3aff", "author": "Jason Fried", "title": "Sometimes it's better, sometimes it's worse", "content": "Failure is a word worth eliminating from your vocabulary. There’s no reason to think about things that didn’t work out as failures. Yet, it’s especially pervasive in entrepreneurial circles. It’s almost as if failure has been fetishized. Nearly worshipped as a right of passage, a prerequisite, a required step on the way. I’m not here to say everything works out. Most things don’t. Plenty of things I’ve poured time and attention into never went anywhere. It can be disappointing. And, depending on what went into it, and what you're left with, it can put you in a perilous spot. But, for your own good, it’s best to relativize things like this — especially when the odds are perpetually, and naturally, stacked against you. Collecting losses, and becoming a connoisseur of catastrophe, won’t help you get a win next time around. So, what instead? For me, it’s a simple shift. I’ve always just felt that some stuff works out better than other stuff. I think that’s the healthiest way to think about it. Just a drop of relative recognition is all it deserves. I also don’t think you’ll find that many lessons looking back on what didn’t work. You probably don’t really know why it didn’t work anyway. It feels good to imagine you do, but there isn’t a long history of people doing the same thing again, swapping this one wrong thing for another presumed right thing, and turning it all around. But if it was so easy to see what went wrong on reflection, shouldn’t there be turnaround stories everywhere you look? More likely, it a swirling confluence of decisions, ideas, events, timing, conditions, and serendipity that drove it off the map. It’s easy to reflect comfortably on convenient assumptions about the past, but real reasons happen in present conditions. So yeah, some stuff works out better than others. That means some stuff doesn’t work at all. But it’s not a failure, and it doesn’t need a name. It just didn’t pan out as you hoped. Move on, look forward, learn by doing and not reviewing, and get on with it. Next time isn’t that time again, it’s a time that never happened before. -Jason", "date": "2024-06-28T18:18:17Z", "url": "https://world.hey.com/jason/sometimes-it-s-better-sometimes-it-s-worse-c601264c"}
{"id": "95ab19d8-0ad6-40bb-bed2-a4d99fcd0c12", "author": "Jason Fried", "title": "Software defaults", "content": "One of my favorite things about designing software is designing the defaults. The defaults define the experience for everyone out of the box. And, therefore, for most people in perpetuity. Convention over configuration rules the day. To me, everything it could possibly do is less interesting than what it does right now, factory fresh. At 37signals we call this The Golden Path and we discuss it often. If a customer followed our lead, stayed in the grooves, and did exactly as the software suggested, what would that experience be like? That's the one nearly everyone will have, so making it great is our top priority. Certainly some will take the path least traveled. Others will head to whatever gear icon they can find and start turning the dials and pulling the levers. And then there are those who enjoy figuring out how to break things by imagining every exception or edge case, and seeing how the app handles it. It's great to have these customers too! But they aren't the ones that pay the bills. Most buy something they just want to work. Configuration is a drag, not a desire. Setting something up brings them down. They just want their struggle out of the way, and choosing and buying the thing was the majority of the work they signed up for. The rest should just glide. Defaults aren't just about nailing The Golden Path, it's also about choosing one. What experience do we want people to have? What opinions do we want to carve into the product? It's not just what we're trying to do, it's what we're trying to say. So if you really want to know what a company thinks about their product, their customer, and the experience they imagine is the best one, just roll with the stock product. Don't mess with it, use it as is. That's the best way to know what something's really like, what was intended, and experience a pure point of view. -Jason", "date": "2024-06-26T19:03:30Z", "url": "https://world.hey.com/jason/software-defaults-15955a8e"}
{"id": "d11440a9-347f-4a8a-9579-e83ba59a19b9", "author": "Jason Fried", "title": "Thoughts on the search for life", "content": "Just listened to Lex Fridman and Sara Walker talk about the origins of life, the search for life, what is life, etc. It was a wonderfully refreshing, nourishing conversation. https://www.youtube.com/watch?v=wwhTfyX9J34 It made me want to spill out some random thoughts on the subject. I’m unqualified, but I’m curious. Our search for life off this planet is inherently primitive. We search for life based on our definitions, using instruments designed to detect what we already know. And who can blame us? It would be impossible to look for what we wouldn’t recognize in a way that we can’t realize. It wasn’t until the 17th century that we even discovered microbial life. And microbial life is the most plentiful life on earth, far surpassing the biomass of plant, animal, and fungal life combined. There’s more of it than anything, and we’ve always been living among it, yet we didn’t know it was here. But it wasn’t just that. Since we share a common ancestor with microbial life, we didn’t find new life, we found an earlier version of who we were. Imagine a microbe evolving so much intelligence that it forgot where it came from, only to invent instruments billions of years later to find itself again. That’s what happened. How beautiful is that? Maybe it will happen again. If we find life elsewhere, we might be discovering a more advanced version of ourselves. Or if life finds us, it might rediscover its primitive origins. If we can forget and lose our history once, why couldn't we forget and lose our future again? It makes me think about what other forms life could take. And how we might never be able to detect it. Let’s imagine that thoughts were a form of life. They feel like it. They mate, they multiply, they evolve, they consume us, they drive us, they make us move, they seem to be born, they seem to die. They seem to have their own agency, appearing in your mind whether welcome or not. But you can't see thoughts. You don't even know a thought exists until you, or someone else, has it. Maybe thoughts are location-based, waiting in every place. To discover one, you can’t look for it. Rather, you  have to be where it is. Imagine what it would be like to stand on Mars, looking back at Earth. But if you were actually there, you’d almost certainly have a thought you couldn’t have here. Insights incompatible with any earthly experience. Questions that couldn’t be contemplated without standing on Martian sand. From Mars, the Earth is mirror. From Earth, Mars is a mirror. Both mirrors, but each perspective reflecting entirely different thoughts. You can’t see the same view or have the same thought from the other place. You must be there to meet thoughts living there. Maybe thoughts don't exist in time and space but in mind and place. This specific mind, in that specific place. Then imagine trying to look for thoughts with our instruments and techniques. Nothing would register. Trillions of thoughts unnoticed, unaware. They can’t be measured, they can only be experienced. How could we ever find them without having them, without being there, without being them? We search for life as if it's something to be found. But perhaps there's something even more alive, beyond our current understanding. -Jason", "date": "2024-06-22T23:26:22Z", "url": "https://world.hey.com/jason/thoughts-on-the-search-for-life-7bb9c6e6"}
{"id": "f138f79a-ffd3-4871-86eb-6e4db4642257", "author": "Jason Fried", "title": "Lighten your grip", "content": "I recently took up drumming. Again. One of the first things you realize, other than you suck, is that you’re gripping the sticks too hard. A tight grip denies certain degrees of freedom, limits subtlety, and ups the fatigue factor. Plus you give up the gift of bounce the drum heads happily offer. It’s like you’re constantly paying interest vs. borrowing for free. I had the same experience when learning to play guitar. It’s like I was trying to choke the neck to death. Clenching the neck makes every change a three step process: Release, move, and clamp down again. It’s slower, it’s harder, and it’s a lot less natural than a flowing motion up and down the neck, pausing to play, rather than stopping. It’s a curious thing. We tend to hold on too tightly early on. It seems to be part of learning just about anything. It's in the nature of starting. When you don’t know what you’re doing, at least you know how to squeeze. But then, you discover that making progress requires you to release a little, to lighten up on your grip. A big part of what you see when you watch someone great is what you don’t see. Tension is notably absent. Instead, a certain ease, a gentle fluidity. A grace, not a grind. This shows up everywhere. To let go is to get somewhere. -Jason —— A great tip via Jack Nicklaus: \"He said hold the golf club like you would hold a bird. Tight enough it won’t fly away but not so tight you’d hurt it.\" (via https://x.com/kadavy/status/1795594760989909128 )", "date": "2024-05-28T23:05:19Z", "url": "https://world.hey.com/jason/lighten-your-grip-724c37a3"}
{"id": "634d4d48-f9f0-44d6-8e16-03297ef4a980", "author": "Jason Fried", "title": "Separation", "content": "In my experience, a key skill to develop is the ability to separate one thing from another. To prevent the small from becoming the all. Take a policy, for example. Could be a government, or a school, or a home owner’s association, or something at work. Whatever it is, you don’t like it. You don’t agree, you don’t like the decision maker, you don’t like how it was enacted, pick a reason, it doesn’t matter which. When you don’t like something, there’s a tendency for that one thing to become everything. Now you don’t like the whole government, Or the whole school. Or the whole association. Or the whole company. Or, if it’s a specific problem with a product, then the whole product is a problem. Is it? Or is it you? Not you as in you did the thing, but you dissolving the membranes, turning a complex organism back into a single cell. It’s psychologically simpler to cast an opinion collectively than it is specifically, but in the end, that easy street often leads to a dead end. It’s easy to feel “I’m pissed”, but really, just part of you is pissed. At that same time, another part of you loves your partner, another part of you is excited about the trip you’re about to take, another part of you is nervous awaiting the results of a recent blood draw, another part of you is focused on the current task, another part is hungry for lunch. We contain multitudes, and recognizing that you’re a thousand things rather than your most obvious emotion is a step towards maturity. Take something your friend said recently. You kinda can’t believe they said it. Shocked, even. They’re on that side? They took that take? Ok, let’s say they did. Now, do you let it bleed into everything else you think about them? You could, but I’d suggest that’s your problem, not theirs. What about the other things about them? They’re your friend, after all. You got here somehow, and it wasn’t because of the things you didn’t like about them. There’s a good chance all the good stuff is still the good stuff. The relationship has more depth now. In this context, complexity is a gift. Now replace friend with government or group or company or product or organization. Developing the ability to tease things apart helps you compartmentalize the less desirable from the more desirable, and see the whole map, with all its separate states of like and dislike, favorable and unfavorable. There’s a very good chance that when you do that, you’ll like a lot more than you despise. Kids know this, then it seems they — we — forget it. Kids like their food separated. Don’t let the blueberries touch — CONTAMINATE! — the chips. Don’t let the carrots graze the sandwich. Don’t let the cookies touch the cheese. This way they can HATE the carrots, but love their lunch. In an absurd way, it seems like the healthy approach. Separate. Distinguish. Decouple. Isolate. Differentiate. One thing’s rarely everything, unless you make it so. -Jason", "date": "2024-05-10T18:07:03Z", "url": "https://world.hey.com/jason/separation-162a4b53"}
{"id": "669afb45-0ebf-4bb1-8555-bbfa27f7b06d", "author": "Jason Fried", "title": "Why am I still doing this?", "content": "I’ve been doing this for 25 years, so I’ll often be asked why I’m still in it and how I stay motivated. It ain’t the money, as I’ve been fortunate enough to make more than I’ll ever be able to spend. I enjoy the work and we have a great crew, each a true pleasure to work with. I remain filled with ideas. So that’s part of it. But it’s more that than. It’s more of a justice thing, really. Look at this screenshot. This is software my neighborhood uses to manage guest parking passes. It’s shit. Maybe you recognize it, maybe you don’t, but the name doesn’t matter. You know what the company charges for the privilege of using it? $10,000/year. $10,000 A YEAR! $10,000 year after year of our HOA budget goes to this crap. It feels borderline criminal. I’m still doing this because the world is flooded with overpriced, crappy, subpar software. It hurts people and it hurts the economy. I feel a moral obligation to do what I can to replace bad options with great options, at vastly reduced prices. I even want to replace great options with equally great options, just at reduced prices. Good software should not be expensive. Software is an absolute miracle. You can make exceptionally good stuff at exceptionally reasonable prices. It’s not like hardware manufacturing where you have to cut all sorts of corners to keep costs in check, or charge a ton for stuff that’s truly well made. Raw materials, machinery, manufacturing, tight tolerances, physics — this stuff costs a lot to get right. Software does not. Yet bad — and great software, frankly — remains way over priced.  And some is absolute highway robbery. Like this parking pass software. It’s clear no one cared about it — it’s just built to some spec by people who will never use it. It’s all there, the features tick the boxes, and technically it works, but we’d never ever find it acceptable if it was a physical product. But since it’s software, it can suck and we can still be sold on a $10,000/year contract. This fuels me. So hell yeah I’m motivated. And the more bad stuff I bump into, or even great stuff with silly numbers attached, the more motivated I get. It’s a deep well that keeps on providing. To that end, we’ve just started working on two more new products this year. We’re on a tear. We’re going to keep on putting quality stuff out there at reasonable prices. Not just to prove that it can be done, but because it must be done. -Jason", "date": "2024-05-03T20:04:00Z", "url": "https://world.hey.com/jason/why-am-i-still-doing-this-b931cdf8"}
{"id": "91d94226-0943-45f3-bc3a-34b9fce0b15b", "author": "Jason Fried", "title": "Osmo Wiio: Communication usually fails, except by accident", "content": "Osmo Wiio was a Finnish researcher of human communication. His laws of communication are the human communications equivalent of Murphy’s Laws. Wiio's laws state... If communication can fail, it will. If a message can be understood in different ways, it will be understood in just that way which does the most harm. There is always somebody who knows better than you what you meant by your message. The more communication there is, the more difficult it is for communication to succeed. And I particularly like his observation that anytime there are two people conversing, there are actually six people in the conversation: Who you think you are Who you think the other person is Who you think the other person thinks you are Who the other person thinks they are Who the other person thinks you are Who the other person thinks you think they are. I'd say he's spot on across the board. -Jason", "date": "2024-04-26T17:06:54Z", "url": "https://world.hey.com/jason/osmo-wiio-communication-usually-fails-except-by-accident-73a8ff2b"}
{"id": "b4075dd3-f0b9-4b98-91af-b71df9142739", "author": "Jason Fried", "title": "Surface area vs. Depth in product design", "content": "Some of the most rewarding features to add to products are ones that don’t increase surface area, but increase depth. This is how you continue to make a product a whole lot better without it feeling like it got a whole lot bigger. Basecamp’s new References feature is a great example of this. Video + write-up: https://updates.37signals.com/post/new-in-basecamp-references Barely any surface area — just a subtle tab down by the comments section. It’s almost not even there. Easy to ignore if you aren’t interested, but click that tab and a whole world of connections opens up. That’s the depth. All the sudden you can see how this is related to that, who’s referenced it across the entire system, how recently it’s been discussed (is it “alive” or “dead”), and where the energy is around the topic. Surface area vs. Depth. An important thing to internalize when designing products. -Jason", "date": "2024-04-13T20:56:42Z", "url": "https://world.hey.com/jason/surface-area-vs-depth-in-product-design-eabd0cb4"}
{"id": "c1ee8d16-fa24-493f-8e10-70cbe8cc317b", "author": "Jason Fried", "title": "Motivation", "content": "I can fake enough. I can fake a lot. But I’ve noticed there’s one thing in particular I can’t fake: Motivation. And in the end, at least for me, it all comes down to motivation. I may have the talent, I may know the tricks, I may be able to go through the motions. But if I deeply don’t want to do it, it won’t be good. Simple as that. It might get done, or more likely it may not, but it’ll be hollow. Something will be missing. And that’s the spiral — doing empty work dissolves my motivation even more. I’m more likely to do something I’m terrible at if I really want it, than something I’m great at that I don’t. Motivation is my essential element. And you can’t mine it. It mines you. -Jason", "date": "2024-04-04T16:08:20Z", "url": "https://world.hey.com/jason/motivation-50ab8280"}
{"id": "a71a4705-321f-4f56-ad51-7972ae1b1567", "author": "Jason Fried", "title": "Avoiding pile-ups", "content": "One of the reasons we work in six week cycles, is that it gives us a different definition of later. When you work on really long projects — say 3, 6, 9 month projects — or projects that don’t have any end in sight, “we can do that later” typically means you’ll get to it eventually, as part of the current project. Long time frames give you invisible space to pack away unrealistic amounts of work. Since later is so far away, there’s no harm in kicking the can down the line. In other words, later makes a pile at the end. Gnarly problem you can’t figure out how to solve yet? Punt it into the later pile. Design not coming together quite right? Toss it in the later pile. Taking on lots of technical debt as you go? Push it into the later pile. But then as you near the end, you run into this big pile of stuff you said you’d eventually deal with, fix, redesign, tighten up, etc. But there rarely seems to be enough time at the end, so you either end up guiltily ignoring it entirely, or hastily patching it together with duct tape. And when you hastily patch, you often end up creating another fix-it-up project later. But, when you work in six week cycles, or relatively short time frames, later means something else entirely. There’s no time for later. It’s now or not. Later doesn’t mean we’ll get to it at the end of this cycle. It means we’ll drop it. Later means another time, not this time. Later isn’t an obligation, it’s a maybe. Later isn’t a cage, it’s freedom. It’s not a debt to pay off, it’s an asset. There’s no pile of pile ups, there’s no guilt, there’s no feeling of late nights and crunch time ahead. Later simply means not now, not soon, and not for sure. That’s the kind of later we like. -Jason", "date": "2024-03-14T16:31:06Z", "url": "https://world.hey.com/jason/avoiding-pile-ups-88f71f6b"}
{"id": "7bb6a566-98e8-4d71-8f73-890c18f30ed0", "author": "Jason Fried", "title": "Hooks, towel bars, and software", "content": "Strangely, a recent bathroom renovation crystalized my perspective on product development. When being asked to choose between towel hooks or a towel bar, the choice was obvious: Hooks, of course. Hooks take up no space. Towel bars suck up space. Hooks hold towels no matter how you place them. Towel bars require towels to be balanced lest they slide off. Towels naturally look good and drape well on hooks. Towels on bars require effort to display well. Hooks can hold anything with a loop or a bend or a catch — loofas, shower caps, hats, rain soaked jackets and backpacks, etc. Towel bars can’t hold nearly as much, even though they take up much more space. Hooks can hold multiple towels at once, with enough air getting to multiple layers because of the uneven ridges that single point hanging creates. Towel bars layer wet towels, leaving ones at the bottom or middle struggling to dry. You can’t mount a hook crookedly. You can absolutely mount a towel bar unevenly. Reasons go on. But what do towel hooks have to do with product development? For me, just about everything. They’re a frame, they’re a lens, they’re aspirational. A hook holds more than towels — it holds lessons in how to build. We aim to make hooks. I want our products full of hooks. Simple, flexible, you-can’t-do-it-wrong hooks. Hooks that just work, no fuss. When working on new products, new features, and improving existing stuff, I’m visualizing the “hook-ness” of what we're building. Making small, flexible features with minimal surface area that can be used intuitively in obvious ways without the possibility of doing it wrong. That’s the magic formula, that’s our model. The unassuming, humble hook is a high bar. -Jason", "date": "2024-03-03T22:14:08Z", "url": "https://world.hey.com/jason/hooks-towel-bars-and-software-14c66c8c"}
{"id": "23085e93-09cb-4ee5-b823-25ec0bdbfad6", "author": "Jason Fried", "title": "Do learn", "content": "Imagine teaching guitar without putting an instrument in someone’s hands. Or teaching ceramics without having people work with clay. Or teaching tennis without swinging the racket and hitting balls. I’m sure there’s some way to teach those things without doing those things, but come on, we all know you have to do those things to really learn those things. I believe business is in the same category. It’s much closer to learning an art, sport, or instrument than it is to learning history, political science, or another subject primarily taught through written texts, lectures, or observing without doing. Yet how many entrepreneurship programs out there require their students to start a real business? They may exist, but I’ve been around and haven’t seen one yet. It can be the simplest damn business — buying and selling on eBay, for example — but it’s got to be a business with costs, products or services, and sales to customers. And it should start on day one, class one, and go at least as long as the course allows. The businesses that are started, and the struggles and successes that ensue, should be the subject matter, period. Instead, there’s a lot of talk. There’s a lot of abstraction. There’s a lot of strategizing. There’s a lot of business plan writing. There’s a lot of game play. There’s a lot of theorizing. And there are plenty of case studies. But there’s very little guitar being played, clay being formed, and balls being hit. Imagine learning guitar by planning how you’re going to play. Or learning how to throw a pot on a wheel by presenting a Powerpoint on it. Or learning how to keep the ball in the lines by studying how the lines were painted. We’d roll our eyes. And rightfully so. Yet this is how entrepreneurship is taught. Heads should roll. And rightfully so. Give me two people — Person A has spent two years in business school studying how to start a business that doesn’t yet exist. Person B has never set foot in business school, but has been running their own business for two years. Who’s learned more about entrepreneurship along the way? Who has the advantage in year three? I know who I’m picking. You? To learn business, do business. -Jason", "date": "2024-02-27T17:20:20Z", "url": "https://world.hey.com/jason/do-learn-54ece4d4"}
{"id": "60663484-075e-42e3-a8e9-f006e42abfc7", "author": "Jason Fried", "title": "You couldn't know", "content": "Have you ever been asked \"What do you wish you knew then that you know now?\" I have. And I hate the question. It's usually framed in a way that encourages you to pretend to place yourself in the nascent days of your career, or early adulthood. Back when you didn't know much, when you were trying to figure things out. Essentially it's asking you which mistakes you wish you didn't make. To squint and identify the things you could have bypassed if you were armed with the wisdom of hindsight. My take? I think you’d have made the same mistakes, and I don’t think you could have avoided anything that happened. Why? First, it assumes you'd even listen to your 50 year old self when you were 20. Next it assumes you'd even be ready and able to accept the advice you didn't recognize as relevant. Last it assumes you'd be able to avoid the things you didn't see coming. I don't think you could, would, or should. Learning is experiencing and doing. It’s not dodging, following, or forgoing. You had to go through the shit to learn the shit. Sidestepping it would have just landed you in some other shit. And then you'd have wished you had listened to different advice. You wouldn’t have your sage advice today if you hadn’t had the stupid experiences then! In fact, answering the question would erase present you from existence. Because if you were different then, you wouldn’t be the you you know now. Are there mistakes I wish I hadn’t made? One one hand, absolutely — plenty — but on the other hand, I had to make them to be who I am now. There’s no version of me that’s present me today with a different set of events in the past. I like who I am now, even with portions of my past I’m less satisfied with peering through present day goggles. But it’s a fantasy to think that if I’d just had magical advice from some old dude named me, then I wouldn’t have made those mistakes back then. Cut yourself some slack. -Jason", "date": "2024-02-21T22:05:21Z", "url": "https://world.hey.com/jason/you-couldn-t-know-3d98330d"}
{"id": "aee49026-47fd-438a-a03e-62ffb1431c07", "author": "Jason Fried", "title": "Don't delegate your word", "content": "As you build your business, you'll end up delegating plenty. Much of what you did before is now better done by someone else. To make more progress, you release your grip and allow. But there’s one thing you should hold tight and never let go. It’s the thing that should never be delegated. It’s your voice. Speak for yourself. Don’t let anyone speak for you. Don’t have someone else Tweet on your behalf. Or write posts under your name. Or take your calls. Or read or respond to your emails. No assistant. No replacement. No simulation. How can you take someone at their word when it's not their word? The moment it’s not you to someone on the other end, you’ve lost something you’ll never get back. If they write you, and they don’t get you back, you’ve gone wrong. Yes it’s more work. But it’s your work, and your obligation. You = you is the equation to solve. Don’t outgrow that. -Jason", "date": "2024-02-20T20:02:12Z", "url": "https://world.hey.com/jason/don-t-delegate-your-word-1875de99"}
{"id": "a964fbe8-c9c3-4b0e-bfbc-d33c0d3843a2", "author": "Jason Fried", "title": "The data came from where?", "content": "Now you have the data. Thousands of responses from a survey with dozens of questions. You worked hard to come up with questions that painted the picture you felt you needed to make the decision with the data you gathered. And now you've got it. Comprehensively. Quantitatively. You're data driven, and now you have the stuff that drives you. You're more sure than ever. But wait a second. Where did that data come from? Your survey, yeah... But where did the questions come from? Best practices? Opinions on what to ask and how to ask it? According to who? Are you sure those words before the question marks were the right ones? What if the questions were asked differently? So much certainty coming out, so little going in. \"How often do you...\" vs \"How often would you...\" vs. \"Last week did you?\". The responses to those could be wildly different. Did you check your words as closely as you checked your results? If you slide back a few steps, you'll see that it's all a judgement call. How you asked, what you asked, when you asked, which words you paired together, how you started the question... All these things matter. In fact, they are the matter that form the answer. And you know what? There's no right way. Which is the exactly the point I'm trying to make. Your hard data comes from subjectivity. A sense of solidity built from mush. False confidence at the finish line, from a shapeshifting starting line. It's all a judgement call. Even the stuff you can measure. And it's a beautiful thing. -Jason", "date": "2024-02-07T21:00:33Z", "url": "https://world.hey.com/jason/the-data-came-from-where-a82d198d"}
{"id": "216956aa-2050-40f7-8f11-05eb95190aa1", "author": "Jason Fried", "title": "Making it balance", "content": "One of my greatest pleasures at work is trying to find that point where everything feels just right. Nothing more, nothing less, but right there in the pocket. It's almost fractal. It's there in every component, in every feature, in every flow, in every sequence, in every product, in every decision, inside everything across the company. How do you know when it's just right? It's the same feeling you get when you try to balance something physical. You know it. You put something on something else and try to find that center of gravity... A bit to the right, oops too much. Lean back to the left... Steady... Steady... Ugh, too much push. Stack it up again, find that center... Wobble, bobble, almost... And then it locks in. Da! There it is. All the sudden the pushing and pulling forces disappear and it's just there, on its own. Still, in harmony and equanimity. That's what just right feels like. It's easy to experience physically because our bodies speak the language. We feel the weight, we intuit the momentum. Our internal gyroscopes sense  balance, and transfers it into objects we touch. But when it comes to intellectual, conceptual things like business or software, we have to shift into the imagined sense of balance. We don't get the free borders, edges, weights, shapes, and gravity, to help us find that middle. Muscles don't pull on tendons don't pull on bones. Our nerves don't get the signals for free. So I imagine. If this was physical, would it balance? I literally think about the center of gravity of an idea, a feature, a button, an idea, a product. Is there too much weight over here? Too much over there? If this whole thing was in stone, would it crash to one side? Or would it stand a chance of staying upright? Would it be at rest, or would it want to fall? Once you find that spot — the right set of features, the right flows, the right yesses and the right no's, you stop. That's v1. Once you find the balance, you aim to stay in balance. Adding more, but in a balanced way to maintain the form, to keep the center. To hold steady. It's a beautiful thing. That's how I think about making products. -Jason", "date": "2024-02-05T21:29:15Z", "url": "https://world.hey.com/jason/making-it-balance-5056a8fb"}
{"id": "c02ee5eb-8b6c-4f6c-8bd0-2eeb717ce344", "author": "Jason Fried", "title": "Basecamp turns 20", "content": "20 years ago today I wrote a blog post that changed my life. I'd never really launched a product before, so posting to our blog was only way I knew how to do it. And social media hadn't even been invented yet, so where else was I supposed to put it? In fact, guess what else happened to launch the same day as Basecamp? Facebook. So we're talking the stone age. I was announcing this new thing we built called Basecamp . It was a project management tool that we made for ourselves. At the time we were a web design firm, and we just didn't have a good way to collaborate with each other and keep our clients in the loop. We didn't have a place to make announcements, keep feedback on the record, and generally keep things centralized in a way that would keep everyone accountable. We figured if we needed it, plenty of others probably did too. And it turns out they did! We were right. Not only was Basecamp something entirely new at the time, the distribution model, and business model, were new too. We weren't the first to offer software as a subscription service, but we were very, very early. So early in fact that the bank wouldn't allow us to accept annual payments on credit cards because they didn't want to be on the hook if this new software as a subscription service model thing didn't work out in a few months. That's why we could only initially bill monthly! Which turned out to be a pretty good thing in the end. You never know what's going to happen until after it happens. And happen it did. We had this idea that, I don't know, if we could maybe make $5,000 a month after the first year, we'd be on to something. That would be a nice $60,000/year business, which we'd feather into our web design business. We'd essentially treat it as a perpetual client — we being our own client. Turns out that we hit that $5000/month mark in a few weeks. And a year or so later, Basecamp was generating more revenue for us than our web design business. So we shut that part of the business down and went all-in on Basecamp. And software in general. So much came from Basecamp. And so much still does. Rails came from Basecamp. And tens of thousands of programming careers came from Rails. Other businesses sprang up. Software as a service was further legitimized. And the cycle that began back in the early 2000s continues to spin strongly today. It's been the professional honor of a lifetime to be able to build something that matters to so many, and to build that thing alongside so many extraordinary people, for so many extraordinary people. From co-workers to customers to fellow business owners, and everyone I've met along the way, what an incredible ride it's been so far. And today's Basecamp is the best it's ever been, by far. It's a thrill to watch whole new generation of entrepreneurs, product teams, and small businesses are discovering the secret so many have known: Businesses simply run better on Basecamp . There really is something radically different about it. In this business, longevity isn't a fluke. As 2024 marks 20 years of Basecamp, it also marks 25 years of 37signals . 2024 also marks the beginning of something brand new from us called ONCE . It's our year of new. It'll be interesting to see if we're early again. When you've been around an industry long enough, you get to see how cyclical everything is. The Earth is round, and so are trends. When you're close to something, it looks like it's on a straight line forever, but when you step back, and wait awhile, you'll often see it crest the curve, bend out of view, and eventually sneak back up on you from behind. Oh, that again! I remember that. Yeah, that was good. One of the real treats of a long career is to revisit the past and pull some of those better ideas ahead into the present. Right now it feels like we've got a bag of bright ideas slung over our shoulder. And we're headed out for new horizons. I feel so fortunate, and so grateful. Thank you. -Jason", "date": "2024-02-05T17:52:23Z", "url": "https://world.hey.com/jason/basecamp-turns-20-a34c88e1"}
{"id": "213b3381-7839-4325-ae82-955d5927b581", "author": "Jason Fried", "title": "Enough feedback", "content": "Enough feedback comes quick. Invite 100, get 10, 5 probably tell you all you need to know. Or at least 80% of it, which is all you need to know. Another 10, 20, 50+ will end up telling you mostly the same as those core five. And you'll find yourself repeating yourself — explaining the same thing you already explained, just to new people. Or thanking them for reports you've already received. The stuff that you loved learning the first time becomes irritating after three more people tell you three more times. It doesn't matter if there's a place to see everything that's already been reported — no one's looking at that before they report what's already been reported. It's just human nature. They're just trying to be helpful, they aren't here to check their work. Of course more opinions and perspectives shine new lights through different lenses, but the beams converge on the initial spot provided by that original group of five. Never fault those who share because you asked. You're lucky they care enough to give. But remember that feedback comes fast, and too much of a good thing can create a mess to manage. That's on you, not them. -Jason", "date": "2024-01-31T21:54:27Z", "url": "https://world.hey.com/jason/enough-feedback-ccbc303c"}
{"id": "f67c247d-010b-431c-b09c-e9dba825b0da", "author": "Jason Fried", "title": "It’s all a judgment call", "content": "It's all a judgment call. Every human decision is a gut decision. The decision itself is the messy integration of many disparate pieces of information, experiences, instincts, stories, and unknowns. Data may inform, but as long as a human is making the decision, it's ultimately a judgment call. If you're just going by the data, then you're confirming, not deciding. Machines are better at that than you'll ever be. A decision is a point of view seen through a million lenses, many of which are invisible even to the one deciding. The lenses are formed by every experience that person has ever had, their imagination, and, in many ways, the generations of people that came before them in order for them to be here. An experience doesn't exist without a prior experience. And every past colors every future. Think about it. When companies hire executives, they ultimately hire on experience and judgment. Hiring itself is a judgment call about other people's future judgement calls. Narrow it down to three extraordinary candidates. What sets them apart? It's the stuff gleaned through conversation, not questionnaires or test results. That's why we interview, and don't choose our best algorithmically. Competency is bigger than \"can they do it\". Competency is \"how they do it.\" Can is clean and binary, how is messy and analog. In many ways, the output of any company is that company's collective judgment about what to do, how to do it, why to do it, and when to do it. Each one of these is a loose collection of prior judgment calls made by individuals, all unique in their own experiences. Give 10 companies the same data, the same facts, and the same amount of time, and you're going to still have 10 different outcomes. Because all those clean binaries are transmuted through the messy analog that is judgment. At least that's what I think. -Jason", "date": "2024-01-17T05:02:29Z", "url": "https://world.hey.com/jason/it-s-all-a-judgment-call-6ab5d025"}
{"id": "8b25fdaa-2fe6-4d1b-8052-b187ab388ac9", "author": "Jason Fried", "title": "Apple Vision Pro POV", "content": "The thing that excites me most about the Apple Vision Pro is the ability to capture someone's point of view. General purpose vision tracking at this scale and resolution, in a consumer device, is entirely new thing. And I think it has the potential to alter the course of the human experience. Cameras can record a scene. Video cameras can record many scenes at a high frame rate. And a skilled photographer or cinematographer / director duo can direct your gaze at a specific point, region, or sequence. And that's resulted in amazing pictures, movies, and visual experiences. But what I think is super interesting about the Apple Vision Pro is the potential to be able to literally see through someone else's eyes. Not just see their field of vision — you can get at that with head or eyeglass mounted cameras — but to actually see where they're looking. To know what they're focused on. To lock in with them. To see how they see. To watch them look from their point of view. Standing in someone's shoes is one thing, but even if you could do that, you'd still be looking through your own eyes. But to literally see as they'd see from someone else's point-of-view perspective feels groundbreaking. If I was making an app for this, I'd call it \"See With\". Imagine being able to see with an artist. What do they look at when they paint? Where are they looking? How are they looking? How often are they darting around, vs. fixing their focus on a specific spot? When they choose a brush, are they looking at the toe, the belly, or the heel of the brush? Or is the right handle they're after for the control they seek? Imagine being able to see with a furniture designer. What do they look at specifically when they look at a piece of wood? How do they see the grain? When do they look at the whole vs. the tiniest detail. How do they see their tools. How do their eyes help them make their choices and decisions? Imagine being able to see with a florist. What part of the flower are they looking at? What catches them? When they look at entire bouquet, what bits do they focus on first? When they're looking through 36 roses, how do they see those? What are they looking at to pick that specific one? Imagine being able to see with a programmer. When they look at code, what do they see? Where are they looking? What are they looking for? How often are they referencing this bit or that bit? Do they continually read through the entire thing like a story, or are they just focused on one line at a time? How do they spot a bug? Same with a writer. A drummer. A driver. A fly fisherman. A landscape designer. A tailor. The list goes on. I'd find this endlessly fascinating. Add in voiceover where someone can describe what's going through their head while they work, choose, consider, and see, and you've got a first-person observational learning experience that's radically new. I hope this happens.", "date": "2024-01-16T23:09:31Z", "url": "https://world.hey.com/jason/apple-vision-pro-pov-d6ffafaf"}
{"id": "4bb91802-9ab4-498d-b8cb-e35c6be26497", "author": "Jason Fried", "title": "Swimming the center or the edge", "content": "Imagine a vast swimming pool 25 miles long, 50 miles wide, and 25 feet deep. Swimming this pool is akin to running a business. And how you swim this pool is akin to how you run the business. Everyone starts at the beginning, but you decide how close to the center or the edge you swim. There’s only one rule: You can’t turn around, there’s no going back. Where would you start? Given the dimensions of the pool, here’s how I’d do it: I’d start near the edge. The edge effectively creates multiple “shores”. You can swim all the way to the end, or you can grab the side and stop for a breath, a break, or even decide “that’s enough” and stop there. This is optionality. More points of survival. To me this represents independence. But not everyone decides to start at the edge. Oftentimes, a key strategic decision pushes them center: Raising money. And the more money they raise, the further center they’re pushed. At some point, there’s only one way to make the business work: To reach the other side. Once you begin, the edges are further away than the end. There’s no optionality, you can’t stop. You either make it across, or you die. The choice between VC funding and bootstrapping independently depends on an entrepreneur's appetite for risk and personal definition of success. VC funding is typically for those who aim for a singular, large-scale “win”, while bootstrapping appeals to those seeking path with multiple potential outcomes along the way. One wants it all, while the other wants enough. Realistically, there are other places to start than just the edge or the center. You can start further center but still closer to the edge. But the further center you go, the more risk you take, and the fewer options you have. Every entrepreneur has to figure out what makes sense for them, but for me, optionality is worth more than one big outcome. What about you? -Jason", "date": "2024-01-12T18:09:43Z", "url": "https://world.hey.com/jason/swimming-the-center-or-the-edge-a61c6187"}
{"id": "d60f937d-54ac-410d-b3bf-6acad1c4439c", "author": "Jason Fried", "title": "To make", "content": "I've consulted. I've done client work. I've advised. I've served on boards. I've invested. I've written books. I've spoken on the circuit. I've blogged for years. I have to say, I've found no greater professional joy than working with a tight group of people to ship and support our own products . And for those products to find people willing to trade their own hard earned treasure for a little bit of ours. Betting on an idea — and seeing it through — is enormously fulfilling. The creative and intellectual stimulation is beyond compare. Especially when you're the first customer for anything you make. When I was a consultant doing work for hire I thought it was the peak. I got to bounce from client to client, sign big contracts, do a lot of work, cash large checks, etc. But then you realize most of what you do is never implemented. Yes, you got paid for it, but it was just advice, recommendations, and suggestions. Words on pages that were received, but not really read. Designs in files that were delivered, but never really deployed. There was nothing there in the end. You didn't get to make any bets, you just played with someone else's chips. You thought you were changing things. Changing them. But it wasn't change, it was an exchange. You handed it over, they handed you something in return, and that was that. I'm glad I went through it, otherwise I wouldn't have known it. Been giving other people advice for years? Give yourself the advice and see if it's any good. Meet the market. Go make something. Join a team that's making something. Put your fingerprint on something that won't just sit on the shelf somewhere. -Jason", "date": "2024-01-03T23:53:19Z", "url": "https://world.hey.com/jason/to-make-5a88817f"}
{"id": "f2ee5128-1ab0-471b-b8eb-287784d1a377", "author": "Jason Fried", "title": "Cars and business", "content": "I’m going to draw a parallel that isn’t quite straight, but it’s close enough. It’s between old (analog) cars and new (digital) cars, simple (analog) businesses and complicated (digital) businesses. Lately I’ve been driving two distinctly different cars. One from 1970, and the other from 2023. They essentially have nothing in common other than that you sit in them, they have four tires that contact the road, and you control them with a steering wheel and pedals. Some who don’t care much for cars might say that’s everything in common. On paper I can see the argument, but get behind the wheel of both, and go for a drive, and you wouldn’t say the experiences were equivalent. They’re as different as different can be. The 1970s experience is analog. Your leg strength determines your stopping power. The road surface below clearly communicates with your ass. The steering wheel actually feels like it’s turning the wheels. The windows roll down by turning a crank that literally rolls them down. Switches snick, dials click. This is a direct experience, with mechanical feedback, requiring full attention and real effort. The 2023 experience is digital. Nearly everything is abstracted. The brakes are heavily mechanically assisted. Steering even more so. You can’t really feel the road surface because the suspension masterfully absorbs every little detail. Even the buttons have been replaced by touchscreens with haptics. This is an indirect experience, with simulated feedback, requiring some attention and little effort. Which you prefer is up to you. I happen to love both for different reasons. And that’s just driving. The gulf is wider when it comes to repair. With an old analog car, a problem’s cause is more obvious. Linkages are visible, this connects to that, teeth mesh to move gears which move shafts which move wheels. When something’s broken it’s generally confirmable with a common tool and a set of eyeballs. Any mechanic with a basic understanding can diagnose any problem relatively easily — sometime solely by ear. There are only so many things it could be, and they’re all right in front of you. With a modern new car, computers enter the picture. Engines are covered, sometimes even inaccessible. Cars crash, but so does firmware. This doesn’t turn that, this sends electrons to that, which are then interpreted by circuits and software and systems.  Which one’s to blame when something doesn’t work? It’ll take a while to find out, and at least $1000. Almost anything can be wrong, and you’ll have to leave the car at the shop for a while so they can plug it in and run diagnostics. The human defers to the machine to tell us. Pros and cons for sure. Now for the parallels to business. Through this car experience lens, I’ve come to see businesses as either analog or digital too. I’m not describing their product or what they make. I’m talking about how they’re structured, how they run. An analog business can make software, and a digital business can make pizza. An analog business is direct. It’s clear what does what, and how it does it. When something changes, you typically know what changed. There’s some suspension to absorb the bumps, but it’s basic — you’re never too far removed from the root cause. There are fewer managers and more doers. There’s less distance between the customer and the maker. Feedback is heard, not interpreted and translated. No decks, just conversations and writing. A digital business is indirect and abstracted. The structure is obscured, riddled with departments and groups run by other groups. Decisions are complicated because one too many people are involved. What should be simple has become complex — the result of process that serves the prospect, not the purpose. Everything is padded. Getting to someone requires going through something. Customers are a concept, sliced by demographics. Everything’s a presentation rather than a conversation. As usual, the analogies and metaphors don’t map perfectly, but hopefully you feel what I’m getting at. Does it resonate? I aim to run an analog business. Direct, clear, obvious, fair, and easy to fix. -Jason", "date": "2023-12-27T00:46:16Z", "url": "https://world.hey.com/jason/cars-and-business-eea60b8d"}
{"id": "271f0d09-a0cc-4374-8959-ed4b3c85f8d8", "author": "Jason Fried", "title": "Live with it for a while", "content": "In the course of building products, you'll likely experience moments when you're unsure of a certain screen, flow, condition, label, idea, whatever. Maybe this button doesn't feel right. Or the name of this feature feels unresolved. Or some color is jarring, but kind of interesting nonetheless. Or the way something gets set up seems a bit kludgy at the moment. Maybe this stuff is alright, maybe it's not, but it feels unsettled. I like these moments. It's practice. It's a chance to sit with them, to let them be, to work on other things while they marinate in the back of your mind. They aren't blockers, they aren't deal breakers — they're just things that may or may not work out. Sometimes time makes them work. Or reveals that they certainly don't. Sometimes they weren't that important anyway, and it's just a matter of getting used to them. Sometimes they're novel and unusual — which can be jarring to the uninitiated — but endearing to the experienced. Sometimes! So just let them be. Come back around to them later if they continue to bug you. It's perfectly OK to leave things unresolved, and let the resolution force itself on you eventually. If you forget about them, they didn't matter anyway. If you can't forget, maybe they do matter more than you realized. Projects unfold. Live with them for a while. The answers will reveal themselves when they're ready. -Jason", "date": "2023-11-27T21:46:11Z", "url": "https://world.hey.com/jason/live-with-it-for-a-while-a9191f5f"}
{"id": "49036d97-3fc6-4968-a5ad-c369e1c1e463", "author": "Jason Fried", "title": "Commodities, generics, and software", "content": "Once a product category proves popular, it's common for more companies to enter the market. Eventually, many options appear that are essentially mostly the same. Now we've got something that quacks like a commodity. Once we've got a commodity, generics eventually follow. Devoid of fancy packaging, marketing, and advertising, prices fall while quality remains perfectly acceptable. Brand name products might be slightly better on some dimensions, but it ultimately becomes a value judgement. A few bucks difference? The confidence of buying a brand name still feels worth it. Many, many bucks different? Maybe not. This happens in most industries. Maybe not in airplanes, but absolutely in peanut butter. And you know what's closer to peanut butter than airplanes? Software is. Strangely, many software categories have commoditized, but, given that nearly everything is a service these days, operational costs have remained universally high. This makes it hard for lower priced generics to creep in. This means people continue to pay luxury prices for software services that are essentially commodities. We think something's wrong with that. Sounds like an opportunity. This is where ONCE comes in. One facet of our initial strategy with ONCE is to find those commoditized pay-forever services everyone's running, and make our own radically simplified \"80/20\" versions as pay-once products. And this time you get to own for less, not rent for more. And you'll get the code, too. In about a month we'll unveil the first ONCE product. Any guesses? -Jason", "date": "2023-11-16T17:37:55Z", "url": "https://world.hey.com/jason/commodities-generics-and-software-393ccf10"}
{"id": "83cd0a73-51c9-42f2-a91d-4b966be01907", "author": "Jason Fried", "title": "Heard Something, Read Something, Saw Something [#16]", "content": "Hey there! Here’s the 16th installment of my popular Heard Something, Read Something, Saw Something series. So, what do we have this time... Heard Something Lately I've been enjoying listening to discussions about free will. Do we have it? If so, how much? Always? Sometimes? Never? Is it real or an illusion? I find the concept fascinating. One of my favorite recent conversations (debates?) about the topic was between Russ Roberts and Robert Sapolsky on Robert's EconTalk podcast. Listen in. Hear it: https://www.econtalk.org/robert-sapolsky-on-determinism-free-will-and-responsibility/ Read Something Every once in a while you read something that swirls with someone’s body of work and undeniably signals they definitively know what the fuck they’re doing. This is that, by Jonathan Hoefler. Read it: https://typography.com/blog/text-for-proofing-fonts Saw Something Driving Dreams is a wonderful documentary on the golden age of Italian automotive design. Full of colorful characters, poetic stories, and the celebration of an art form — and approach — that's now long gone. Well worth the 52 minutes. See it: https://www.amazon.com/Driving-Dreams-Gianluca-Migliarotti/dp/B07455DCH7/ Until next time. BTW, if you like these, and think someone else might too, please forward it on. They can subscribe to my newsletter right at the top at https://world.hey.com/jason . Thank you. -Jason", "date": "2023-11-08T18:48:50Z", "url": "https://world.hey.com/jason/heard-something-read-something-saw-something-16-afce97da"}
{"id": "1f14b6f7-e84d-48c1-8e31-2bf68e27fa29", "author": "Jason Fried", "title": "Look back less", "content": "I have a theory. One of the reasons companies have a hard time moving forward is because they've tangled themselves in the near past. Eyes aimed backwards rather than ahead, staring at the dark, feet in their own concrete. They've trapped themselves looking for certainty where there isn't any. Searching for actionable advice where there are only guesses. Something sorta went wrong. A project didn't go as planned. Some launch didn't meet expectations. A number someone felt was in reach didn't get hit. So they look back, scanning the ruins for something shiny. They gather people up and call for a search party. They launch into post-mortems and retrospectives. It's a mistake most of the time. And a waste of time almost all of the time. Let's start with when it makes sense. If the process is highly mechanized, isolated, or systematized, then you can look back and find the exact moment when something went wrong. And you don't need to conjure up a \"what if\" counterfactual, you know for sure this was the point of failure. For example, if you're making widgets, and your small circular disks are coming out as half moons instead, then you can trace the process back, figure out where the stamping went wrong, correct that machine or process, and absolutely 100% fix the issue. If you can do that, by all means do that. Technical downtime can often be perfectly traced like that, too. But so many failed projects subject to retrospectives are searching for reasons where there are only humans to be found. Ever been on one that lasts hours only to determine \"next time we need to communicate better\"? I bet you have. Or one that says \"If we only would have involved QA earlier we would have caught that.\" Or \"Next time we need to be more careful to take seasonal timing into account\". Or \"designers and programmers need to work more closely together.\" Or some other generalized platitude, extruded from the retrospective process. There may be truth in the statements, but are they really the reason things didn't go as planned? Really? You sure? And those aren't actually answers, they remain questions without question marks. So now what, specifically? Spending hours of people's time grabbing for something grippy in the box of generalized excuses isn't going to turn up a treasure. And most of the time, reasons are actually mysteries. Or deeper than you can dig. Or too many to count. The world, the work, the market, the customer, the timing, the pressure, the economy at large, the expectations, the hopes and dreams are fuzzy, abstract, and irrational. You can point, but not at a point that's clearly defined enough to make a difference next time. Counterfactuals are deeply satisfying because they can never be proven. They never have to smash into reality. Imagination takes hold, a scapegoat comes into focus, and we can blame it all on the thing we'll never know mattered in the first place. Report written, meeting adjourned! A better path is to reflect forward, not backwards. Develop a loose theory while working on what's next. Appreciate there's no certainty to be found, and put all your energy into doing better on an upcoming project. But how will you do better next time if you don't know what went wrong last time? Nothing is guaranteed other than experience. You'll simply have more time under the curve, and more moments under tension, to perform better moving forward. Internalize as you go, not as you went. If you're any good, you'll simply do better next time because you're better at what you do than you were the last time you did it. That may be murky and unsatisfying for some, but I believe it to be absolutely true. So next time the involuntary instinct kicks in, and the urge to schedule a retro when something didn't go as planned, skip it and skip ahead. There's more to learn looking forward. -Jason", "date": "2023-11-03T00:12:53Z", "url": "https://world.hey.com/jason/look-back-less-848e9db0"}
{"id": "71181341-3b88-4ffb-9dd9-b6f50ecfd1d2", "author": "DHH", "title": "Living with Linux and Android after two decades of Apple", "content": "It now seems laughable that only a few months ago, I was questioning whether I'd actually be able to switch off the Apple stack and stick to my choice. That's what two decades worth of entrenched habits will do to your belief in change! But not only was it possible, it's been immensely enjoyable. What seemed so difficult at first now appears trivial, since it's been done. That's not a critique of the Apple ecosystem per se. Apple continues to make great hardware and pretty good software too. And I think accepting that fact from the get go actually makes sticking to a switch more likely to succeed. Falling in love with something new is a better and healthier motivator than hating something old. That's been my experience with Linux in particular. I've come to love the setup I've enshrined in the Omakub project. It does a whole host of things much nicer than the old macOS walled garden experience, on top of the fact that running an open source operating system simply feels right for someone who owes their entire career to open source. It's a positive vision: I really, really like what Linux has to offer these days. It's a similar feeling, albeit not as strong, with the switch to Android. I don't have any illusions that Google is any gentler of a corporate giant than Apple. The two have very similar ideas about extracting monopoly rents from their respective app stores. But the slogan that Android is more open is actually true. Now plenty of people don't really care about that openness, and that's fine. But I do. I care about being able to download the Fortnite APK straight from Epic Games , and being able to play our favorite family game with the kids, without having to ask someone for permission. Sure, it could be a bit more convenient if the game was available in the Play Store, but spending another two minutes doing the direct install is nothing against the hundreds of hours we've spent playing since. The same is true in terms of customization. I'm running this beautiful, minimal launcher called olauncher , which turns Android into a far less addictive mobile experience by replacing icons and app drawers with a simple set of text links. It's great. And it's the kind of stuff you can only really do properly on Android, because replacing the default launcher is possible. Getting out of the Apple rut has also lead me to discover an amazing new world of both software and hardware. Solutions that I just wasn't in the market for after settling into an Apple grove over the years. Since switching to Linux, I've picked up Neovim as my new editor of choice, I've fallen in love with the Framework 13 laptop, and recently, I've even gotten into mechanical keyboards (the current choice being the NuPhy Air75 ). That's what a change of scenery can do for you. Force you to open your eyes to what else is out there. And in turn introduce you to new ways of doing and being. That's a gift in and of itself. Now I'm not telling you any of this to convince you to give up your Mac or your iPhone. People who love their Apple gear aren't going to be convinced by an alternative positive vision because they're simply not in the market for one. That's where I was for a long time. Just not interested. I'm telling you this in case your Apple relationship isn't quite so hunky dory. In case their recent trajectory and relationship with developers might have been bugging you too. Because it's in that situation you really need to know that the alternatives are not just present, they're good . Their value isn't defined as not-Apple. There's no valor in that. Linux is wonderful, is flawed, is messy, is beautiful, is nerdy, is different. Android is customizable, is open, is fragmented, is less polished, is experimental. All the pros and the cons are true at the same time. And it's a compelling adventure to discover whether the trade-offs speak to you. Don't be afraid to take the trip, but give it at least two weeks (if not two months!), and don't think of the journey as a way to find the same home in a different place. Be open to a new home, in a new way, in a new place. You might just like it.", "date": "2024-07-12T09:48:52Z", "url": "https://world.hey.com/dhh/living-with-linux-and-android-after-two-decades-of-apple-4f730084"}
{"id": "f80fcb6e-fd7f-4957-b9b6-ca17425500c4", "author": "DHH", "title": "Visions of the future", "content": "Nothing gets me quite as fired up as discovering the future early and undistributed. That feeling of realizing that something is simply better, and the only reason it hasn't taken off yet is because the world hasn't realized it. It's amazing, and it's how I'm feeling about Linux right now. That \"how did I not know it was this good\" sensation. I felt the same way about the Mac back in 2001. And Ruby in 2003. And company chat with Campfire in 2005. And, fast forward, now with #nobuild, Hotwire, and even exiting the cloud. When I discover a path that seems like a clear shortcut, it doesn't really matter if it's poorly paved at first. As long as it appears to take us somewhere better, laying the bricks and clearing the brush is incidental. It's about seeing that end state. Where what's right in front of us now, rough and unpolished as it may be, can be transformed, if we put in the effort, that inspires me to keep going. Yes, half the fun is the adventure. We should always be pushing toward new horizons, even if some of them inevitably will end up in dead ends. But the other half is watching things genuinely compound for the better. Take web development. It's incredible how much conceptual complexity we've been able to compress in the last decade, and particularly in the last half of a decade. It wasn't just one thing, it was all the things. It was browsers getting better, mobile CPUs getting faster, #nobuild becoming possible, Hotwire showing an alternate route. Each substantial, yes, but together epoch altering. A new dawn. Following such a sense of wanderlust requires a certain disagreeableness. Even arrogance. A steadfast belief that it's possible that you might actually have found a better way. Whether that turns out to be true or not. You have to believe that it's possible. That the market place of ideas isn't perfectly efficient or perfectly rational. That it hasn't priced it all in, and that you could invest in upcoming concepts for an intellectual profit. You're never going to be right about everything, but a life spent without taking at least a few bets on being early on an idea is one not lived to the fullest. Dare a little. Roll the dice every now and then. Come along for an adventure whether its heads or tails.", "date": "2024-06-08T06:16:45Z", "url": "https://world.hey.com/dhh/visions-of-the-future-2e23ff85"}
{"id": "a9e2f628-47e9-4531-a1ef-acfb2f10032e", "author": "DHH", "title": "Introducing Omakub", "content": "Linux can look and feel so good, but it often doesn't out of the box. It's almost like there's a rite of passage in certain parts of the community where becoming an expert in the intricacies of every tool and its theming is required to prove you're a proper nerd. I think that's a bit silly, so I created Omakub: An opinionated web developer setup for Ubuntu . Omakub turns a fresh Ubuntu installation into a fully-configured, beautiful, and modern web development system by running a single command. No need to write bespoke configs for every essential tool just to get started or to be up on all the latest command-line tools. Omakub is an opinionated take on what Linux can be at its best. Omakub includes a curated set of applications and tools that one might discover through hours of watching YouTube, reading blogs, or just stumbling around Linux internet. All so someone coming straight from a platform like Windows or the Mac can immediately start enjoying a ready-made system, without having to do any configuration and curation legwork at all. This isn’t a project for someone already versed in the intricacies of nixOS or relishing a fresh install of Arch. It’s using vanilla Ubuntu because that’s one of the most widely adopted Linux distributions, and one that is even a pre-install option from many computer vendors. But while Ubuntu has a great package manager in apt, many of the tools that developers want either haven’t been packaged, need more recent versions than what has been frozen in the LTS, or need actions post-install necessary for the best operation. Omakub includes all those scripts needed. But package management is only half the battle of getting a great development experience going on Linux. The other half lies in the dotfiles that control the configuration. Linux gets great power from how customizable it is, but that also presents a paradox of choice and a tall learning curve. Having good, curated defaults that integrate all the many tools in a coherent feel and look can help more developers acquire a taste for Linux, which they may then later inspire a fully bespoke setup (or not!). Nothing in Omakub provides solutions to problems you couldn’t also solve a million other ways. The main benefit is in The Omakase Spirit. The idea that an entire setup experience can benefit from being tailored upfront by someone with strong opinions about what works and looks good together. This doesn’t make the choices necessarily better than other choices. Linux has inspired a million options for a million tastes. That’s great and worthy of celebration. But there’s a large constituency of developers who are more than willing to trade ultimate bespoke customization for a cohesive package of goods, at least until they understand what all the options are and have fully bought into making the switch to Linux. Omakub is for all these future Linux users.", "date": "2024-06-06T14:29:39Z", "url": "https://world.hey.com/dhh/introducing-omakub-354db366"}
{"id": "f05546df-9a45-4ae3-8aec-91e8cc4eeeb1", "author": "DHH", "title": "Why I retired from the tech crusades", "content": "When Ruby on Rails was launched over twenty years ago, I was a twenty-some young programmer convinced that anyone who gave my stack a try would accept its universal superiority for solving The Web Problem. So I pursued the path of the crusade, attempting to convert the unenlightened masses by the edge of a pointed argument. And for a long time, I thought that's what had worked. That this was why Ruby on Rails took off, became one of the most popular full-stack web frameworks of all time, inspired countless clones, and created hundreds of billions in enterprise value for companies built on it. But I was wrong. It wasn't the crusade that did it. Since those early days, I've talked to thousands of programmers who adopted Ruby on Rails back then, and do you know what virtually every one of them cite? That original 15-minute blog video . Which didn't contain a single comparison to other named solutions or specifically pointed arguments against alternatives. It just showed what you could do with Ruby on Rails, and the A/B comparison automatically ran inside the mind of every programmer who was exposed to that. That's what did it. Showing something great, and letting those who weren't happy with their current situation become inspired to check it out. Because those are the only people who are able to convert to your cause anyway. I've never seen someone who was head'over'heels in love with, say, functional programming be won over by arguments for objected-oriented programming. You simply can't dunk someone into submission, and it's usually counterproductive if you try. But you can absolutely attract people who aren't happy with their current circumstances to give an alternative a chance, if you simply show them how it works, and allow them to conclude by themselves how it would make their programming life better. What I've also come to realize is that programmers come in many different intellectual shapes and sizes . Some of those shapes will click with functional programming, and that'll be their path to passion. Others will click with vanilla JavaScript, and be relieved to give up the build pipelines. Others still will find their spirit in Go. This is great. Seriously. The fact that working for the web allows for such diverse ecosystem choices is an incredible feature, not a bug. I found my life's work and passion in Ruby. I have friends who've found theirs in Python or Elixir or PHP or Go or even JavaScript. That's wonderful! And that's really all I want for you. I want you to be happy. I want you to find just that right language that opens your mind to the beautiful game of coding in your most compatible mode of conception, as Ruby did for me. This is not the same as just saying \"everything has trade-offs, use what works best\". That to me is a bit of a cop out. There is no universal set of trade-offs that'll make something objectively \"work best\". Half the programming conundrum lies in connecting to an enduring source of motivation. I wouldn't be a happy camper if  I had to spend my days programming Rust (but I LOVE so many of the tools coming out of that community by people who DO enjoy just that). It also doesn't mean we should give up on technical discussions of advantages or disadvantages, but I think those are generally more effective when performed in the style of \"here's what I like, why I like it, so look at my code, my outcomes, and see if it tickles your fancy too\". Programming is a beautiful game. I would give up all the fancy cars I have in a heartbeat, if I was made to choose between them and programming. The intellectual stimulation, the occasional high from hitting The Zone, is such a concrete illustration of Coco Chanel's \"the best things in life are free, the second best things are very expensive\". Programming is one of those \"best things\" that is virtually free to everyone in the Western world (and increasingly so everywhere else too). So let's play that beautiful game to the best of our ability, in the position that flatters our conceptual capacities the most, and create some wonderful code.", "date": "2024-06-02T21:56:33Z", "url": "https://world.hey.com/dhh/why-i-retired-from-the-tech-crusades-107a51ea"}
{"id": "03438bce-2b21-456c-bdb7-945132032efb", "author": "DHH", "title": "Linux as the new developer default at 37signals", "content": "For over twenty years, the Mac was the default at 37signals . For designers, programmers, support, and everyone else. That mono culture had some clear advantages, like being able to run Kandji and macOS-specific setup scripts. But it certainly also had its disadvantages, like dealing with Apple's awful reliability years , and being cut off from seeing how half our Basecamp customer base saw by default (since they're on Windows!). Either way, it's over. Apple is no longer the exclusive default at 37signals. Going forward, we're working to make Linux the default for developers and system operators (and welcoming Windows back in the mix for accounting/marketing). I've personally been having a blast over the last few months digging deeper and deeper into the Linux rabbit hole, and it's been a delight discovering just how good its become as developer platform. Not one without its flaws, obviously, but an incredible proposition none the less. This has left me with little interest in going back to a commercial operating system as a daily development driver. My entire career has been spent in the service and sun of open source, both as a contributor and a beneficiary, and closing the loop with a desktop operating system is very satisfying. Default doesn't mean edict, though. First of all, we have a great mobile team that simply needs to be on Apple hardware to develop for Apple platforms. That's not changing. Neither is the fact that some people will have a strong personal preference to stick with the Mac. Totally fine too. But defaults still matter. Along with assumptions about what's supported and how well. And changing our default to Linux sets a new tone, as well as affords us the institutional weight to support companies like Framework with our business. I love voting with my dollars for more of a future I'd like to see, and Framework represents just that. The end result will be a company that has people running Mac, Windows, and Linux. Which is great from both the perspective of living how your customers do, but also escaping the trapped feeling of a mono culture built around an Apple that we, and many other developers, are increasingly at odds with . None of this has to be binary. Hate/love. Yes/no. Sure, Apple has evolved into a company that's much harder to recommend for people who care about the future of computing, but they still make great hardware, and the M-chip revolution will continue to benefit anyone who likes computers. So I haven't crushed my MacBook in defiance. We won't be wholesaling out our existing fleet of Apple machines either. But going forward, we'll spend more of our money and attention on platforms that align better with the independence and freedom we so cherish in all other aspects of our business. The year of Linux on the desktop. Who would have thought!", "date": "2024-05-24T16:58:09Z", "url": "https://world.hey.com/dhh/linux-as-the-new-developer-default-at-37signals-ef0823b7"}
{"id": "17b9e82c-e48e-4bd9-aa4c-881bb9a3c994", "author": "DHH", "title": "Beautiful motivations", "content": "Programmers are often skeptical of aesthetics because they frequently associate it with veneering. A thin sheen of flashy marketing design covering up for a rotten or deficient product. Something that looks good from afar, but reveals itself to be a disappointing imitation up close. They're right to be skeptical. Cheap veneers are the worst. But discarding the value of aesthetic on behalf of cheap imitations is a mistake. Not just because truly beautiful objects and concepts inevitably reveal a deeper and designed experience. That's the whole \"I'm writing you a long letter because I didn't have time to write you a short one\". Making something beautiful takes extra steps. Steps that are commonly also associated with extra care the rest of the creation. No, the primary reason I appreciate aesthetics so much is its power to motivate. And motivation is the rare fuel that powers all the big leaps I've ever taken in my career and with my projects and products. It's not time, it's even attention. It's motivation. And I've found that nothing quite motivates me like using and creating beautiful things. I don't think that would come as any surprise to people of the past. The history of creation is in part a tale of pursuing beautiful outcomes and rewards. But in our age, we've managed to deconstruct and problematize so much of what is self-evidently beautiful that it's harder to take the chase for granted. It's in the context of this age that I labor for programmers to rediscover beauty. Beautiful code, beautiful patterns, beautiful tools. Not to create a single, monoculture of aesthetics. That's never going to happen. But to elevate the work of making things look not just good, but sublime. To revel in it, to celebrate it. And beauty isn't binary. It's the journey of a thousand little decisions and investments in making something marginally prettier than it was before. To resist the urge to just make it work, and not stop until you make it shine. Not for anyone else, even, although others will undoubtedly appreciate your care. But for yourself, your own motivation, and your own mission.", "date": "2024-05-20T19:46:14Z", "url": "https://world.hey.com/dhh/beautiful-motivations-6fef7c73"}
{"id": "b23ddf3a-91a0-4404-9ba0-7d114057355d", "author": "DHH", "title": "System tests have failed", "content": "When we introduced a default setup for system tests in Rails 5.1 back in 2016, I had high hopes. In theory, system tests, which drive a headless browser through your actual interface, offer greater confidence that the entire machine is working as it ought. And because it runs in a black-box fashion, it should be more resilient to implementation changes. But I'm sad to report that I have not found any of this to be true in practice. System tests remain as slow, brittle, and full of false negatives as they did a decade ago. I'm sure there are many reasons for this state of malaise. Browsers are complicated, UI driven by JavaScript is prone to timing issues, and figuring out WHY a black-box test has failed is often surprisingly difficult. But the bottom line for me is that system tests no longer seem worth the effort the majority of the time. Or said another way, I've wasted far more time getting system tests to work reliably than I have seen dividends from bugs caught. Which gets to the heart of why we automate testing. We do it for the quick feedback loop on changes, we do it to catch regressions, but most of all, we do it to become confident that the system works. These are all valid goals, but that doesn't mean system testing is the best way to fulfill them. Now I'm not advocating you throw out all your system tests. Just, you know, probably most of them. System tests work well for the top-level smoke test. The end-to-end'ness has a tendency to catch not problems with the domain model or business logic, but some configuration or interaction that's preventing the system from loading correctly at all. Catching that early and cheaply is good. The stickiest point, however, is not testing business logic, which model and controller tests do better and cheaper, but testing UI logic. Which means testing JavaScript. And I'll say I'm not sure we're there yet on the automated front. The method that gives me the most confidence that my UI logic is good to go is not system tests, but human tests. Literally clicking around in a real browser by hand. Because half the time UI testing is not just about \"does it work\" but also \"does it feel right\". No automation can tell you that. HEY today has some 300-odd system tests. We're going through a grand review to cut that number way down. The sunk cost fallacy has kept us running this brittle, cumbersome suite for too long. Time to cut our losses, reduce system tests to a much smaller part of the confidence equation, and embrace the human element of system testing . Maybe one day we can hand that task over to AI, but as of today, I think we're better off dropping the automation.", "date": "2024-05-17T19:29:36Z", "url": "https://world.hey.com/dhh/system-tests-have-failed-d90af718"}
{"id": "4d53aa7c-52ad-4770-831f-a92b6b6f2f08", "author": "DHH", "title": "Paranoia and desperation in the AI gold rush", "content": "I've never seen so much paranoia in technology about missing out on The Next Big Thing as with AI. Companies seem less excited about the prospects than they are petrified that its going to kill them. Maybe that fear is justified, maybe it's not, but what's incontestable is the kind of desperation it's leading to. Case in point: Slack. So Salesforce just announced that they'll be training their Slack AI models on people's private messages, files, and other content . And they're going to do so by default, lest you send them a specially formatted email to feedback@slack.com . I mean, really, feedback? It's the kind of process that invites a quip about some knuckle-sandwich feedback to their face. But I digress. Presumably this is because some Salesforce executives got the great idea in a brainstorming sesh that the way to catch up to the big players in AI is by just ignoring privacy concerns all together. If you can't beat the likes of OpenAI in scanning the sum of public human knowledge, maybe you can beat them by scanning all the confidential conversations about new product strategies, lay-off plans that haven't been announced yet, or private financial projections for 2025? I mean imagine the delight some CEO might feel when they start typing out the announcement to lay off 30% of the workforce, and Slack autocompletes the text with the most anodyne distillation from five competitors doing the same? All you have to do is edit out, say, Asana in your layoff completion, and voila, you'll have saved at least 8 minutes typing out the corporate slop yourself. Whether the vision of that gleams bright or dystopian probably depends on how well your inner compass is tuned to the kind of AI KPIs pushing product managers in charge of acquired chat products at large tech companies. But the more interesting point to me is what this says about the broad paranoia and desperation in the AI gold rush. Things are moving fast enough that we'll probably see more such flagrant transgressions of trust and privacy, if there's even a sliver of a chance that it can provide an edge in the race for a better chatbot. Buckle up!", "date": "2024-05-17T15:25:28Z", "url": "https://world.hey.com/dhh/paranoia-and-desperation-in-the-ai-gold-rush-33042dbc"}
{"id": "81f7df43-d064-428e-9bec-ab4322830baf", "author": "DHH", "title": "Open source is neither a community nor a democracy", "content": "Using open source software does not entitle you to a vote on the direction of the project. The gift you've received is the software itself and the freedom of use granted by the license. That's it, and this ought to be straight forward, but I repeatedly see that it is not (no matter how often it is repeated ). And I think the problem stems from the word \"community\", which implies a democratic decision-making process that never actually existed in the open source world. First of all, community implies that we're all participating on some degree of equal footing in the work required to further the welfare of the group. But that's not how the majority of open source projects are run. They're usually run by a small group of core contributors who take on the responsibility to advance the project, review patches, and guard the integrity of the vision. The division of labor isn't even close to be egalitarian. It's almost always distinctly elitist. That's good! Yes, elitism is good, when it comes to open source. You absolutely want projects to be driven by the people who show up to do the work, demonstrate their superior dedication and competence, and are thus responsible for keeping the gift factory churning out new updates, features, and releases. Productive effort is the correct moral basis of power in these projects. But this elitism is also the root of entitlement tension. What makes you think you're better than Me/Us/The Community in setting the direction for this project?? Wouldn't it be more fair , if we ran this on democratic consensus?? And it's hard to answer these question in a polite way that doesn't aggravate the tension or offend liberal sensibilities (in the broad historic sense of that word -- not present political alignments). So we usually skirt around the truth. That not all participants in an open source project contribute equally in neither volume nor value, and this discrepancy is the basis of the hierarchical nature of most projects. It is not, and never will be, one user, one vote. That is, it will never be democratic. And this is good! The democratic ideals are fulfilled by the fact that open source is free and full of alternatives. Don't like how they're running a given project? Use one of the usual countless alternatives. Or start your own! Here, you can even use the work of a million projects that came before you as a base for doing new work. But the reason this doesn't resolve the tension is that it still relies on showing up and doing the work. And there just so happens to be far fewer individuals willing and capable of doing that than there are individuals who wish they had a say on the direction of their favorite software. You can't solve that tension, only acknowledge it. I've dealt with it for literally twenty years with my work on Rails and a million other open source projects. There's an ever-latent instinct in a substantial subset of open source users who will continuously rear itself to question why it's the people who do the most work or deliver the most value or start the most projects that get to have the largest say. And when people talk about open source burnout, it's often related to this entitlement syndrome. Although it's frequently misdiagnosed as a problem of compensation. As if begging for a few dollars would somehow make the entitlement problem bearable. I don't think it would. Programmers frequently turn to the joy of open source exactly because it exists outside the normal employment dynamics of quid-pro-quo . That's the relief. I frequently argue that open source is best seen as a gift exchange , since that puts the emphasis on how to react as receiver of gifts. But if you're going to use another word as an alternative to community, I suggest you look at \"ecosystem\". Ecosystems aren't egalitarian. There are big fish and little fish. Sometimes the relationships are symbiotic, but they're also potentially parasitic. But whatever word you choose, you'd do well to remember that open source is first and foremost a method of collaboration between programmers who show up to do the work. Not an entitlement program for petulant users to get free stuff or a seat at the table where decisions are made.", "date": "2024-05-16T19:41:37Z", "url": "https://world.hey.com/dhh/open-source-is-neither-a-community-nor-a-democracy-606abdab"}
{"id": "b177f402-d569-40af-a5b2-dbf2f44e930e", "author": "DHH", "title": "Meta is shutting down Workplace", "content": "The saying \"nobody ever got fired for buying IBM\" is at its essence about risk management. The traditional wisdom goes that if you buy from a big company, you're going to be safe. It may be more expensive, but big companies project an image of stability and reliability, so buying their wares is seen as the prudent choice. Except, it isn't. Certainly not any more. Meta killing Workplace is merely exhibit #49667. Any company that hitched their wagon to Workplace just got served with an eviction notice. In a about a year, the data will go read-only, and shortly after that, it's game over. Now companies from Spotify to McDonalds, along with millions of others, have to scramble to find an alternative. Simply because Meta can't be bothered to maintain a platform that's merely used by millions when their consumer business is used by billions. This, right here, is the risk of buying anything from big tech like Meta and Google. Their main ad-based cash cows are so fantastically profitable that whether it's the millions of paying accounts on Workplace or the millions of live websites once hosted by Google Domains , it all just pales in comparison, and is thus one strategy rotation away from being labeled \"non-core\" and killed off. Buying from big isn't the sure bet they want you to believe. Buy from someone who actually needs your business to make the wheels go round.", "date": "2024-05-14T21:57:54Z", "url": "https://world.hey.com/dhh/meta-is-shutting-down-workplace-3e24bca5"}
{"id": "f1a1183b-3e92-4cc1-a65d-1b9be3087cf3", "author": "DHH", "title": "The endangered state of normality", "content": "When I was growing up in the 80s and 90s, I had friends who were socially awkward nerds, friends who were cool but didn't like school at all, friends who were good at school but couldn't muster the will to finish their math homework, and friends who were tomboys. None of these kids ever got a diagnosis. They were all well within the spectrum of what constituted \"normal\" back then. Today all of them would likely have acquired some label of pathology because nobody seems to qualify (or desire to be seen) as being normal these days. This is the natural consequence of \"centering the margins\". Of making it socially desirable to be not normal and low status to be regular. And it's happening across everything from gender expression to neurodiversity. There's cachet of cool to be had in identifying with some margin. Preferably one that can claim to be oppressed by society via heteronormativity or neurotypicality or other big words for \"normal\". And, as Abigail Shrier documents in Bad Therapy , there's a large industry of therapists and other \"mental health professionals\" eager to accommodate this flight to the margins. Eager to supply the diagnosis, the pills, the reassurance of how every phase of experimentation or misbehavior can be explained by some big word of pathology. I think we've given up on something important in this pursuit of individuality through the spectrum of marginalization. When fitting is less about having the right brand of backpack and more about having some medical prescription. Whatever is at play, I think we're better off re-expanding the definition of normal  to fit a much broader spectrum of quirky, weird, and natural varieties of humans. Fewer labels, reserved for far more severe predicaments, and fewer interventions, left for those where the risks of medicalized action far outweighs the risk of iatrogenic treatment.", "date": "2024-05-14T17:51:52Z", "url": "https://world.hey.com/dhh/the-endangered-state-of-normality-d632a7fe"}
{"id": "6d1dccb4-6bbf-4b1b-9b7d-6a00052cffff", "author": "DHH", "title": "DEI is done (minus the mop up)", "content": "In November of 2022, I wrote about the waning days of DEI's dominance , and enumerated four factors that I saw as primary drivers of this decline. Those waning days have now been brought to a close, and DEI, as an obsessive, ideological preoccupation of the corporate world, is done. Witness this tabulation of DEI (and ESG) mentions in earnings reports, reported by Business Insider : It's over. And thank heavens for that! This graph perfectly captures the temporary insanity of what those nutty years were really like in corporate America. An explosion of sanctimony, triggered by the fallacy that racial disparities in the office (and elsewhere) could only be explained by systemic racism. And, worse still, that the way to counteract this mirage was by compensatory discrimination against \"model minorities\" ( mostly Asians ) and \"whiteness\", as prescribed by the dogma of Antiracism . And with this explosion of sanctimony came a brief but suffocating culture of intimidation. Anyone who dared question the theology of high priests of this new religion, like DiAngelo or Kendi, were hounded and frequently banished by ideological thugs. It didn't matter if the hounded were low-level employees who hadn't kept up with latest woke dictionary (is it latinx now? or latine? or? ), executives who dared to claim that meritocracy might actually be a good thing, or comedians making jokes about the insufferable fake piety of it all. There were pitchforks enough to chase all transgressors, big or small. But now it's done. The tide has turned. The People are sick of this shit. So that's it. All there's left to do is mop up, then make sure we harden our defenses for the next time agitating embers come flying.", "date": "2024-05-10T14:22:55Z", "url": "https://world.hey.com/dhh/dei-is-done-minus-the-mop-up-b3bbbb64"}
{"id": "697d58fb-c3bb-4a83-8bd9-a9301fdd5157", "author": "DHH", "title": "Hating Apple goes mainstream", "content": "This isn't just about one awful ad. I mean, yes, the ad truly is awful . It symbolizes everything everyone has ever hated about digitization. It celebrates a lossy, creative compression for the most flimsy reason: An iPad shedding an irrelevant millimeter or two. It's destruction of beloved musical instruments is the perfect metaphor for how utterly tone-deaf technologists are capable of being. But the real story is just how little saved up goodwill Apple had in the bank to compensate for the outrage. That's because Apple has lost its presumption of good faith over the last five years with an ever-larger group of people, and now we've reached a tipping point. A year ago, I'm sure this awful ad would have gotten push back, but I'm also sure we'd heard more \"it's not that big of a deal\" and \"what Apple really meant to say was...\" from the stalwart Apple apologists the company has been able to count on for decades. But it's awfully quiet on the fan-boy front. This should all be eerily familiar to anyone who saw Microsoft fall from grace in the 90s. From being America's favorite software company to being the bully pursued by the DOJ for illegalities. Just like Apple now, Microsoft's reputation and good standing suddenly evaporated seemingly overnight once enough critical stories had accumulated about its behavior. It's not easy to predict these tipping points. Tim Cook enthusiastically introduced this awful ad with a big smile, and I'm sure he's sitting with at least some sense of \"wtf just happened?\" and \"why don't they love us any more?\". Because companies like Apple almost have to ignore the haters as the cost of doing business, but then they also can't easily tell when the sentiment has changed from \"the usual number\" to \"one too many\". And then, boom, the game is forever changed. I think this is bound to come as a bigger surprise to Apple than it would have almost any other company. Apple had such treasure chest of goodwill from decades as first an underdog, then unchallenged innovator. But today they're a near three-trillion dollar company, battling sovereigns on both sides of the Atlantic, putting out mostly incremental updates to mature products. Nobody is lining up with a tent to buy a new iPhone any more. The Vision Pro had at best a mediocre launch. Oh, and now the company is even the creator of cringy ads, introduced by a cringy CEO. Not that this is a mortal wound or even a story anyone is likely to remember in a month. But it is an early indicator that Apple's run on easy street is over. And that's going to require a new approach, which Apple probably won't embrace until they've embarrassed themselves a few more times (like they did with another cringe ad from a little while back). Everything is great until it isn't.", "date": "2024-05-09T00:34:49Z", "url": "https://world.hey.com/dhh/hating-apple-goes-mainstream-fe740007"}
{"id": "a251214b-006e-4862-9fb0-0417a1be4abd", "author": "DHH", "title": "The last RailsConf", "content": "Few numbers exemplified the early growth of Rails like attendance at RailsConf. I think we started with something like 400-600 attendees at the inaugural conference in Chicago in 2006, then just kept doubling year over year, as Rails went to the moon. If memory serves me right, we had something like 1,800 attendees in 2008? It was rapid, it was wild, but next year, it'll be over. RailsConf 2025 will be the last RailsConf . This is for the best. RailsConf, as it exists today, is a legacy from when the Rails ecosystem didn't have its own guardian institution. For many years, it was left to Ruby Central to fill this role, but that was always going to be a secondary pursuit to their primary mission of furthering Ruby in general. But now we have The Rails Foundation , which is focused 100% on Rails, backed by the biggest names in ecosystem. It's also the organizer of Rails World , which just sold out its own thousand-attendee conference in Toronto this coming September -- in less than twenty minutes ! The baton has been passed. This is good. With Ruby Central focusing their efforts on general-purpose Ruby endeavors, like maintaining Bundler and RubyGems, as well as putting on RubyConf , the division of responsibilities between it and The Rails Foundation is now clear. Which makes it much easier for both organizations to collaborate on furthering Ruby on Rails, each putting emphasis on their side of the conjunction. I'm going to choose to remember RailsConf for all the wonderful memories it brought me and the ecosystem, especially in the early years. Working with the original crew of Chad Fowler, David A. Black, and Rich Kilmer was the treat of a lifetime. We bootstrapped something from nothing, turned it into an epoch-defining event, and I delivered some of my most memorable keynotes in that era. It's a bit of a shame what happened later , during those mad years in and immediately following the pandemic, but that kind of nonsense is thankfully now largely behind us, not just in the Ruby world, but in tech in general. And Ruby Central is now almost entirely run by people who didn't have anything to do with that debacle anyway. Making it much easier just to look forward, and simply appreciate that those odd years helped motivate finally getting The Rails Foundation off the ground. Either way, the future of Rails shines incredibly bright. The ideal of the one-person framework has never been more relevant. The world has woken up from the ZIRP years with a complexity hang-over , and Rails is the perfect painkiller. From #nobuild to bare-metal deployment to the eternal appeal of a full-stack solution comprised by Active Record, Action Pack, Active Support, and the million other arguments and assets that underpin the modern appeal of Rails. We never went away, but the renaissance is palpable none the less. So I raise my glass to the final RailsConf. Let's go out with a bang in 2025, celebrate the legacy, and then keep plucking away on spreading the joy of beautiful code, incredible productivity, and programmer-centric development with Ruby on Rails. Cheers!", "date": "2024-05-07T17:41:08Z", "url": "https://world.hey.com/dhh/the-last-railsconf-c6188593"}
{"id": "ed6840e3-943e-4b42-9ee1-dbc2fe4c00c2", "author": "DHH", "title": "Magic machines", "content": "There's an interesting psychological phenomenon where programmers tend to ascribe more trust to computers run by anyone but themselves. Perhaps it's a corollary to imposter syndrome, which leads programmers to believe that if a computer is operated by AWS or SaaS or literally anyone else, it must be more secure, better managed, less buggy, and ultimately purer. I wish that was so, but there are no magic machines and no magic operators. Just the same kind of potentially faulty bits and brains. A great example of this was the feedback to our declaration that we're bringing continuous integration back to developer machines . The most common objection was to invoke \"it works on my machine\", as to imply that developer machines were somehow a different breed than the ones running in the cloud or the data center. They really aren't! The computer running tests remotely is indeed just that: Another computer. It isn't magical, and it's no less prone to be reliant on unaccounted for dependencies or environmental factors. In fact, when it comes to testing, it's a feature not a bug to have the suite run on multiple machines. It's like an extra fuzzy check that will uncover undeclared dependencies, and help you produce a more resilient system. Because even the best CI setup isn't production. And just because it works in CI doesn't mean it'll be free of issues in production. Which leads us to the whole point of testing systems in the first place: It's about confidence, not certainty. The road to programmer misery is paved with delusional aspirations that you can ever be fully, truly certain that any sufficiently complicated system will ever work as intended in production. All you have is degrees of confidence to trade-off against increasingly cumbersome protocols and procedures. There's no such thing as 100% test coverage that's meaningful and achievable at the same time. And it's the fundamental lack of confidence in their own abilities that lead programmers to think that the people operating their cloud computers are so much smarter or better than they are. They rarely are. They're just hidden, and it's that opaqueness that false implies a higher competence. If only you knew what kind of frazzled mechanical turk it takes to run most cloud institutions or SaaS operations, you wouldn't be so quick to doubt your own abilities. There's no magic class of computers and no magic class of computing clerics. \"It works on my computer\" is just the midwit version of \"it works on THAT computer\". It's all just computers. You can figure them out, you can make them dance.", "date": "2024-04-30T15:32:01Z", "url": "https://world.hey.com/dhh/magic-machines-10c534bd"}
{"id": "44030398-3fb2-484a-b150-084ff17639e6", "author": "DHH", "title": "We're moving continuous integration back to developer machines", "content": "Between running Rubocop style rules, Brakeman security scans, and model-controller-system tests, it takes our remote BuildKite-based continuous integration setup about 5m30s to verify a code change is ready to ship for HEY. My Intel 14900K-based Linux box can do that in less than half the time (and my M3 Max isn't that much slower!). So we're going to drop the remote runners and just bring continuous integration back to developer machines at 37signals. It's remarkable how big of a leap multi-core developer machines have taken over the last five-to-seven years or so. Running all these checks and validations in a reasonable time on a local machine would have been unthinkable not too long ago. But the 14900K has over 20 cores, the M3 Max has 16, and even a lowly M2 MacBook has 8. They're all capable of doing a tremendous amount of parallelized work that would have seem fantastical to do locally in the mid 2010s. HEY is a pretty substantial code base too. About 55,000 lines of Ruby code, which is verified by some 5,000 test cases along with another 300-some system tests. Virtually all of these tests go through the full-stack and hit the database. These are not mocked to the hilt. To me, the most satisfying part of the improved performance of modern developer CPUs is the possibility to simplify our stacks. Installing, operating, and caring for a remote CI setup is a substantial complication. Either you do it on your own hardware, and deal with that complexity directly, or you pay through the nose for a cloud-based setup. Getting to flush all of it down the simplification drain is an amazing step forward. In fact, it's what I like most about paying attention to the progress of our platforms. Oh, browsers now have really good JavaScript and CSS engines? Awesome. Let's go #nobuild . Oh, developer CPUs now have dozens of cores? Sweet. Let's pull CI home . Oh, single-core performance is way up? Wonderful. Let's drop gotcha-hinged accelerators like Spring . As always, the simplified future is not evenly distributed. I can't see the likes of Shopify or GitHub being able to run the full battery of tests against their millions of lines of code locally any time soon. But 99.99% of all web apps are much closer to HEY in breadth than they are to those behemoths. And small teams ought to remove all the moving parts possible. Never aspire to a more complicated stack than what your application calls for. So we need to keep burning those bridges of complexity once we get to the other side. I can't wait to set fire to every single one of the remote continuous integration bridges we have here at 37signals. Progress is a bonfire.", "date": "2024-04-29T18:40:53Z", "url": "https://world.hey.com/dhh/we-re-moving-continuous-integration-back-to-developer-machines-3ac6c611"}
{"id": "87d6d22c-709d-4024-9efc-38d0f08b9ef9", "author": "DHH", "title": "I could have been happy with Windows", "content": "After more than twenty years on the mac, it was always going to be difficult for me to leave Apple. I've simply not been in the market for another computing platform in decades. Sure, I've dabbled a bit here and there, but never with true commitment. It wasn't until Cupertino broke my camel's back this year that I suddenly had the motivation needed to uproot everything. And when I did, I learned that Windows has turned into a wonderful web developer's platform thanks to the Windows Subsystem for Linux (WSL). I'm not going to lie and say I loved everything about Windows. But after the question of font rendering was settled , and I came to terms with giving up TextMate , it felt perfectly adequate. Better than adequate, actually. It felt nice. Nice knowing that there was a real, realistic, and compelling alternative to the mac, and that most of my aversion to Windows was based on outdated facts or misconceptions. So I made the commitment . Only to fall in love with a quirky piece of hardware from a small company called Framework shortly thereafter. That in turn lead to taking another look at running Linux outright, as the AMD chip inside the Framework simply punched harder with the penguin in charge. This coincided with a month-long trip away from home where all I brought was the Framework 13 running Ubuntu. And that taught me two things: Most of the jokes about Linux are true! There are more rabbit holes, more gotchas, and less polish. But I also learned, and this was the real surprise, that I scarcely minded at all! That in fact running Linux, and running into many of the little issues that often entails, was a surprisingly delightful and educational experience. As an example, I've been trying for a while to get my desktop PC, which has an Nvidia 4090 GPU, to work with my Apple XDR 6K monitor, which only accepts Thunderbolt 3. This involved sourcing an exotic Huawei DisplayPort + 2 USB-A => USB C cable . Then learning everything about monitor EDIDs, xorg.conf, kernel parameters, Nvidia driver versions, and about a million other topics that are very close to the metal and very far from the Apple experience (and I still haven't cracked the nut! ). But rather than being frustrated with things not just working out of the box, I embraced the adventure. There's a certain nostalgia here, I'm sure. I grew up with computers that needed far more tender, love, and care to work well. Where IRQ conflicts had to be resolved before the SoundBlaster card would work for Wing Commander. Computers required some assembly, and as IKEA knows , it made us love them more. So here I am. I still have Windows available as a dual-boot option on the desktop, but the Framework 13 has been running Ubuntu exclusively the whole time, it's my daily driver at the moment, and now that I've acclimated, Linux just feels right. I love the Tactile windows manager for Gnome. I've figured out how to easily fill out my PDFs using Xournal++. Typora is giving me that iA Writer-like distraction-free typing experience I've come to love. And, for now, I've come to terms with VSCode. (See my current setup script ). Would I recommend this expedition to everyone? No. I think if the idea of having to occasionally tinker with kernel parameters or display drivers give you nightmares, you probably shouldn't run Linux on your primary computer. But I'd also say that it's hard to know whether you'll find some zen of motorcycle maintenance in knowing how to tighten the timing chain of Ubuntu before you try. Especially if you've been cocooned inside the Apple bubble forever. For a lot of people, Windows is probably the better alternative to the mac. And that's great! We ought to have AT LEAST three good options for personal computing in the modern age, and now I've come to realize that we do. I'm just happy this exodus happened. I learned something new about myself. I tried a million combinations. And I discovered a real affinity for Framework and Ubuntu. I'd invite you to give it a go, if you're in the mood for a trek. Do it not because it is easy, but because it is hard. See what kind of computing stuff you're made of. Oh, and have fun!", "date": "2024-04-26T18:54:39Z", "url": "https://world.hey.com/dhh/i-could-have-been-happy-with-windows-bd4a7d01"}
{"id": "05068d39-8abf-49d7-bb95-93b9921a93bc", "author": "DHH", "title": "The gift of ambition", "content": "The Babylon Bee ran this amazing bit last year: \"Study Finds 100% Of Men Would Immediately Leave Their Desk Job If Asked To Embark Upon A Trans-Antarctic Expedition On A Big Wooden Ship\". Yes. Exactly. Modern office workers are often starved for ambition, adventure, and even discomfort. This is why there's an endless line of recruits willing to sign up to work for leaders like Musk, despite his reputation for being an erratic hard ass. The ambition is worth it. Because real ambition is rare. It's the lack of ambition that fuels the malaise of a bullshit job. Work so aspirationally underwhelming that it's possible to coast and imagine how the world wouldn't be an iota different if the work wasn't done. A perfect recipe for existential dread and despair. But while the stereotype of ambition is indeed someone like Elon Musk (or Steve Jobs, before that), I don't think you literally need to aim for Mars to stir the heart of sailors. Nor do I think you need to be as abrasive or demanding, as the stereotype implies. That's the balance we've been trying to find at 37signals since its inception: The vision of a calm company compatible with ambition. It's not always easy. If you talk for long enough about the fact that 40 hours a week ought to be enough , that vacations should be free of homing beacons, and how it literally doesn't have to be crazy at work , people inside and out your company might soon think that's indeed all there is. That the ultimate goal of the company is to provide a cush and coasting existence. But that's not why I get out of bed in the morning. The aspiration of a calm company is to me exactly the opposite. To prove how much faster and further you can go if you embrace constraints , stay small , and trust skilled professionals to get the job done . That is, the calm company is a method for getting where we really want to go. It's not a destination in and of itself. In fact, I'd rather work in place where it was crazy all the time, if we're trying to get somewhere, than I'd work somewhere perfectly calm that's just spinning the wheels. But the point is that I don't think these objectives are in opposition. Being ambitious and calm is like being smooth and fast. Big, erratic, dramatic movements might feel like they're getting you somewhere, but the stop watch usually reveals the opposite. But what is ambition, exactly? To me, it's a leap of faith. A belief in the possibility of success without all the evidence to justify it a priori. A trust that whatever challenges we'll face between here and there, we'll be able to figure them out. It's a confidence in the strength of human ingenuity. And a bet that it takes a goal just beyond the reach of the plausible to get the best out of us all. That ambition can be applied to all aspects of a project. The timeline, the people, the problem, the tech. To tickle our sense of adventure, some of it has to be daring and bold. Maybe it's not enough people, not enough time, new tech, novel problems. Whatever it is, there must be an x factor, an unknown. If we can quantify it all before we even begin, the ambition disappears. And in that lack of certainly lies the discomfort, lies the leap. Betting on your ability to figure it out means taking a risk. Maybe you won't figure it out! Maybe we really didn't have enough people! Maybe we'll fail. But it's exactly the possibility of failure that gives the effort its meaning and its value. In the lore of Steve Jobs, you'll find plenty of anecdotes from people who really didn't care for how he treated them or their colleagues at times, but who still credit the projects they worked on for him at Apple as the most meaningful ones of their career. I'm sure the same is true with Musk. These encapsulate the paradox that, psychologically speaking, I don't think most people know what makes them fulfilled at work. (But it isn't the ping pong or the free massage.) Without a dash of the unpredictable, we all wither away. The chase for security and surety only works as a thrill if you never truly get there. Our competency only grows when we stretch it slightly beyond its breaking point from time to time. So keep calm, yes, but for all that is holy, carry on by being ambitious.", "date": "2024-04-25T22:15:23Z", "url": "https://world.hey.com/dhh/the-gift-of-ambition-e7b41ffc"}
{"id": "bbb404f1-ca37-497c-9309-5d7dd88a9514", "author": "DHH", "title": "Villains may live long enough to become heroes", "content": "The first tech company I ever really despised was Microsoft. This was back in the 1990s, the era of \"cutting off the air supply\" , of embrace-extend-extinguish , of open source as a \"cancer\" , and of Bill Gates before he sought reputational refugee in philanthropy. What made the animosity so strong was the sense of being trapped. That the alternatives to the Wintel monopoly of the time was so inferior as to essentially require giving up on modern computing. So when Apple released the first Unix-powered OSX machines at the turn of the millennium, I felt relieved. Saved, even. Finally -- FINALLY!! -- a real choice. Apple provided an escape hatch for computing without giving up on modernity, and I came to love them for it. But that was then and this is now. Microsoft has completed an astounding redemption arc since. They've gone from being the sworn enemy of open source to one of the biggest sponsors of it. They've been exemplary stewards of GitHub. They've won the hearts and minds of developers with VSCode fair and square . They've even put Linux inside of Windows with WSL! In short, they've gone from being a villain to a hero in a wide array of domains. Open source most of all. And I love it. They deserve all the accolades. Meanwhile, Apple... Well, I've talked enough about Apple. So let's talk about something new: Meta. I can't say I ever despised Meta, then Facebook, quite like I did Microsoft. But I sure as shit wasn't a fan. And I remain a staunch opponent of targeted advertising, the privacy assault that inevitably comes with them, and what it's done to the web. But I've come to appreciate that there are bigger challenges facing us than invasive ads. Much bigger. Take AI. Zuckerberg's embrace of open source AI, now making headlines with the public release of Llama 3 , is an invaluable counter to the cartel-adjacent bullshit of \"AI safety & ethics\" that would see the likes of OpenAI and Google conspire with governments around the world to determine what math should be allowed to predict the next token. I've seen this movie before, and I'm not interested in a rerun. In fact, Facebook itself was one of the main characters in the previous show. The still going battle over misinformation/disinformation/malinformation, which continues to see the awful fusion of state and platforms through censors and algorithms in controlling The Narrative. Whatever trust I may once have had in objective third-party \"fact checkers\" have long since evaporated from the catastrophic track record of these anything-but-neutral , would-be arbiters of truth. I don't pretend that either of these problems are easy or even that they have solutions. But they certainly have different potential outcomes and trade-offs. Some worse than others. And the prospect of having AI exclusively fine-tuned by the likes of whoever did Gemini or directed by bureaucrats trying to \"save democracy\" by banning the opposition, yeah, no thanks. I'll take my chances with the unadulterated math or speech any day. Which makes Zuckerberg's transformation so important. I think a lot of the naivete he had, as did many, about the role of content moderation, truth arbiters, and platform control has been replaced by high degrees of skepticism. And I certainly think that after being humiliated by Apple via ATT , he's as motivated as anyone to prevent the next frontier of computing to be dominated by anyone (if it can't be himself!). This is good. And it's not good because I have some special insight into Zuckerberg's \"heart of hearts\". I'm sure his dedication to open source AI is as motivated by self-interest as anyone in that position ever was. That's not a bug! It's a feature! Adam Smith saw it clearly in Wealth of Nations from 1776: \"It is not from the benevolence of the butcher, the brewer, or the baker, that we expect our dinner, but from their regard to their own interest. We address ourselves, not to their humanity but to their self-love, and never talk to them of our own necessities but of their advantages.\" We don't need altruism to save us, we need incentives. We need competition. We need free markets for products, platforms, services, ideas, speech, and AI. We need to put the locus of control with consumers and individuals, not bureaucrats and monopolists. That's always going to be the struggle. Whenever we achieve anything close to its ideal, like the marvel of the worldwide web, it constantly has to be guarded against regression. So if Microsoft proves to be aligned with some of those causes some of the time, I shall cheer them on, and I shall quell my quarreling. And if Meta does the same, they too shall receive my praise. (Or so I imagine Smith would sound!). We badly need more powerful champions and heroes of free markets and free thought. Enough that I'm more than willing to commute the sentencing of former villains who've served their time and changed their minds. And enough that I'm comfortable stack ranking my concerns about society, and realizing that targeted ads just aren't as important as the freedoms defined above. Let's go, Zuck. Give 'em hell.", "date": "2024-04-25T17:20:52Z", "url": "https://world.hey.com/dhh/villains-may-live-long-enough-to-become-heroes-6405ae8c"}
{"id": "2686aa21-5dae-4fc4-934a-ea299baea2c0", "author": "DHH", "title": "As we forgive those who trespass against us", "content": "Google's announcement that they're done discussing politics at work widely echoed the policy changes Coinbase and we at 37signals did a few years back. So yesterday, I did two separate interviews with media outlets on the topic. And we spoke in part about those early weeks of reaction to our changes, as Twitter went crazy in response to the story. What was it like to briefly be the main, hated characters on the internet? In the moment, it was awful, but in retrospect, it was a gift. A gift as a mirror, causing me to reflect on how I might have been part of a similar mob, on other topics, in different ways. A gift of a misogi challenge of character, bringing the satisfaction of overcoming a vicious social purgatory. But above all, the gift of knowing who was there for me and who wasn't. It's a cliché, but \"knowing who your friends are\" really is a blessing. We walk through life much of the time without really knowing who'll be there when the going gets tough -- and our guesses are often wrong. Only the moment of truth, a real crisis, can clarify who's who and what's what. And so it did for me. It brought unexpected friends and allies out in the light, and it revealed which friends and acquaintances would rather crawl back in the woodwork than stand by my side. I was surprised on both sides. But while I'll never forget who made what choice, I've committed myself to forgive those who trespassed against me. In that Mike Tyson'esque way of refusing to let any of them change me. I'm certain I've been the weak link in past situations from time to time. I'm certain I've been too lazy or too timid to reach out to support someone who I knew needed it. I don't have many regrets in life, but the ones I have usually fall into this category: I should have been there for someone. Beyond the personal, I think forgiving our trespassers is how we get out of this specific mess. The period from the late 2010s until at least 2022 really was crazy. It swept up so many otherwise kind and caring people into an ideology predicated on dividing us all into oppressors/oppressed, privileged/not, and other false dichotomies and identities. The way out of bad ideas like that is not a vendetta, but forgiveness. We all have the capacity for being swept up in a social movement or mob. But equally, we all have the path of finding our way out again. I think there are a lot of people sitting right now with a nagging sense of regret from what they partook in during that crazy era. Who tried on the cape of being a Social Justice Warrior, but ultimately found it suffocating both intellectually and culturally. That's the reckoning we're going through right now. The worst thing we can do to slow down the rejection of these bad ideas is by forever tarring people who were momentarily taken in by them. Yes, we should absolutely have a vigorous inquiry into the nature of these bad ideas, trace their lineage, and uncover their tragedies. But we can't persecute every individual who in a moment of fear, weakness or ignorance signed on to carry a torch because that's what everyone else was doing at the time. That is to say, it's more important that we expedite and complete the broad societal rejection of bad ideas than it is to pursue every bad actor until the end of the earth. That's exactly why this vicious ideology proved so unstable, and unable to retain the peak of its power. It kept eating its own for ever-smaller transgressions against an ever-shifting doctrine. To beat that nonsense back, the side of sanity has to do the opposite. Be broader, more forgiving, and less high strung. Lead us not into temptation of retaliation.", "date": "2024-04-23T16:55:51Z", "url": "https://world.hey.com/dhh/as-we-forgive-those-who-trespass-against-us-c5979c81"}
{"id": "738ceb1e-dd19-43dd-b92a-bc5033891c6b", "author": "DHH", "title": "We are a place of business", "content": "After the disastrous launch of their Gemini AI , which insisted that George Washington was actually Black and couldn't decide whether Musk's tweets or Hitler was worse, Google's response was timid and weak. This was just a bug! A problem with QA! It absolutely, positively wasn't a reflection of corrupted culture at Google, which now appeared to put ideology over accuracy. Really, really! Anyone watching that shit show would be right to wonder whether one of America's great technology companies had fallen completely into the hands of the new theocracy . I certainly did. But now comes evidence that Google perhaps isn't totally lost, even if an internal war over its origin principles is very much raging. One pitting the mission of organizing the world's information and making it useful against the newspeak Trust & Safety goal of controlling narratives and countering malinformation (i.e. inconvenient truths). This played out in stereotype as 28 Googlers occupied the CEO of Google Cloud's office for 10 hours this week, defaced property, and prevented other Googlers from doing their work. Because Google provides cloud services to Israel, said the occupiers. And thus The Current Thing demanded it be stopped by whatever means possible. (Remember when The Current Thing was that GitHub shouldn't offer its technology to ICE because \"kids in cages\"? Same thing). But then the most amazing thing happened. There was no drawn-out investigation. No saccharine statements about employee's rights to occupy offices, preventing work from happening, or advance their political agenda at work. Nope. They were just fired . Immediately. All 28 of them. Bravo. Google's bottom line? \"This is a place of business\" . And while employees have the lawful right to protest their working conditions, they do not have the right to prevent a business from carrying out its normal course of commerce over a disagreement in politics. So that was that. But it gets better. Google followed up the unceremonious firings by calling an end to employees bringing their politics to the office. Just like Coinbase did , just like we did . The language was spot on : \"But ultimately we are a workplace and our policies and expectations are clear: this is a business, and not a place to act in a way that disrupts coworkers or makes them feel unsafe, to attempt to use the company as a personal platform, or to fight over disruptive issues or debate politics. This is too important a moment as a company for us to be distracted.\" Three years ago, taking a common-sense position like this would have been met with drama and outage in the media and on Twitter. Today I doubt it'll bring more than a ripple outside of a few activist echo chambers on Mastodon. Amazing progress! Note, none of this pertains to what you think about The Current Thing that provided the trigger this time. It could just as well had been BLM, Russiagate, climate change, or a million other hot-button topics that have occupied the role as The Current Thing, and been used to justify these kinds of insufferable activists yelling at their boss. We've not just passed the peak of the nonsense that nearly swallowed corporate America whole, but we're now seeing them repudiate it head on. If Google, with it's employment roster still packed with people sympathetic to the new theocracy, can put its foot down, so can the rest of the Fortune 500 and beyond. It's time they all say: \"This is a place of business\".", "date": "2024-04-19T12:30:50Z", "url": "https://world.hey.com/dhh/we-are-a-place-of-business-a451eddf"}
{"id": "f468f33a-be6c-4d6e-9867-b21a5d154426", "author": "DHH", "title": "Forcing master to main was a good faith exploit", "content": "I never actually cared whether we call it master or main. So when the racialized claims started over how calling the default branch in Git repositories \"master\" was PrObLEmAtIC, I thought, fine, what skin is it off anyone's or my back to change? If this is really important, can make a real difference, great. Let's do it. How naive. This was a classic exploit of good faith, and I fell for it. Changing master to main changed less than nothing. Because nothing was or is ever enough in this arena. As soon as this word battle was won, it was just on to the next and the next ( and the next ). But the upside of being hit by an exploit like this is that you eventually end up with a patch that closes the hole. And rest assured, this hole in our collective good faith is now closed. People are not going to be this gullible twice. I am not going to be this gullible twice. Next time the firewall will be ready.", "date": "2024-04-15T13:46:50Z", "url": "https://world.hey.com/dhh/forcing-master-to-main-was-a-good-faith-exploit-b21ee30c"}
{"id": "49164dfc-4087-4df2-8034-63cf0361b733", "author": "DHH", "title": "Imperfections create connections", "content": "The engine is in wrong place in a Porsche 911. It's hanging out the back, swinging the car like a pendulum. And that's key to why it's the most iconic sports car ever made. This fundamental imperfection is part of how it creates the connection. This is true of mechanical watches too. They're hilariously complicated pieces of engineering that tell time worse than a $20 Casio quartz watch. And that's why we love them. The imperfection of timekeeping, the need to manually wind the things, cements the connection. That's how computers used to feel too. The Amiga, and the Commodore 64 before it, were quirky bread boxes. Using chips named things like Agnus, Alice, Denise, Lisa, and Paula. With clicking, whirring disk drives. The flickering screen when software was loading. As distinctly different from the competition as a Porsche flat-six is from a Ferrari V12. But the quirky is almost all gone from modern day computers. The mac in particular has been massaged to within an inch of perfection, and has thus become harder to connect with. It's a curious contradiction. We strive to make things better and better, but if we succeed, we reminisce of the quirks that used to be. The last MacBook I really loved was the original 11\" MacBook Air. It was full of compromises. A cramped screen. Chips that weren't quite fast enough. An iconic, wedgy design. It was so good because it was also kinda bad. I thought that era was simply gone. But over the last month or so, I've developed much of the same affection for the Framework 13 . Exactly because of all it's compromises and it's quirky design choices. It uses an odd 3:2 display, which is almost as tall as it is wide. In a time when most every other maker has gone 16:9 or 16:10. And it's matte, not glossy. The keyboard has twice the travel of most modern laptops. Giving it almost a vintage feel, which, once you get used to it, is really addictive. It has interchangeable ports?! You can configure the 4 slots with every combination of USB C, USB A, ethernet ports, HDMI ports, and additional storage you desire. Then swap them quickly and easily. An ingenious alternative to dongle life. And to top it off, I've chosen to run Linux on mine full time. I started out dual booting with Windows, but quickly realized that Linux ran faster on this AMD 7840U chip, and I found that Linux gave me everything I needed in more of that quirky style that gives the Framework machine its appeal in the first place. Those are all the good parts, but there are plenty of drawbacks too. Compared to a modern MacBook, the battery is inferior. I got 6 hours in mixed use yesterday. The screen is only barely adequate to run at retina-like 2x for smooth looking fonts. Linux is far less polished than macOS. But somehow it just doesn't really matter. First of all, 6 hours is enough for regular use. If I'm doing more than that in a single stint without getting up, I'll be paying for it physically anyway. And the somewhat cramped resolution has made me fall in love with full-screen apps again, like I used to do with that 11\" MacBook Air. But this is all picking at the parts when the grand story is the sum. This quirky, flawed machine has created a connection I haven't had with a piece of physical computer hardware in a very long time. That's notable! I know this testimony isn't likely to appeal seriously to most mac users. Just like it wouldn't really have appealed to me a year or two ago. I just wasn't in the market for a change. And that's fine. Apple makes really, really good computers these days. Damn near perfect ones. And most people don't care that the 911 has the engine in the back. In fact, they don't care about cars at all, really. They just want to get from A to B, as quickly, cheaply, and smoothly as possible. And they tell time perfectly from their smart phone display. This is the democratization of progress. Wonderful. But if you're the kind of person who might appreciate a slightly notchy manual gearbox, the click of a mechanical shutter on a camera, the ticking of the escapement in a watch, or, dare I say it, putting on a vinyl record, you should checkout the Framework 13. The AMD version starts at just around a thousand bucks. So it's not like you have to switch your whole computing life around to give it a try. And, if you're a programmer, I think you should actually give Linux a try as well. I've smirked about \"This Is The Year of Linux on the Desktop\" for over twenty years, but now that I've been actually running it for over a month, I've realized it's actually here. And probably has been for quite a while. I just run Ubuntu 23.10, and together with ulauncher + tactile , it's a delightful desktop experience (see my whole Ubuntu setup script ). I even found a replacement for my beloved iA Writer in Typora ! Make no mistake, there's more fuss. More snags, more imperfections. So if you go in expecting the same level of perfection you'd get from company worth three trillion, you might be disappointed. But if you consider this the work of a worldwide open source community, it's incredible how close it is in most areas, ahead in a few, and not that far behind in the rest. Dare to add a little imperfection into your computing setup, and you might just find a deeper connection to the bits and electrons running it all. And if you don't, at least you got to see the sun rise in a fun location.", "date": "2024-04-12T07:14:22Z", "url": "https://world.hey.com/dhh/imperfections-create-connections-bc87d630"}
{"id": "a0d9c6f8-e77a-42c8-adf1-ad64926f9543", "author": "DHH", "title": "Enough problems to go around", "content": "The worst kind of company is usually not the one where there's too much real work to do, but the kind where there's not enough. It's in this realm the real monsters appear. Without enough real problems to go around, humans are prone to invent fictitious and dreadful ones. This is the root of David Graeber's Bullshit Jobs analysis. That a shocking percentage of people work jobs that they themselves see little to no meaning in, because the work that's being produced makes no difference, has no essence. It's enough to make anyone mad. Now part of the problem is clearly one of perspective. I'm always amazed by the pride and duty it appears most Japanese workers put into the most mundane jobs. I forget where I read this, but it's the difference between being a happy zoo keeper who think of their job as \"tending to the welfare of the elephants\" rather than just \"shoveling shit all day\". But it's not all subjective either. We are biologically tuned to conserve energy while being cognitively tuned to crave a challenge. So when the load is material, we often wish it was lighter. But if we actually succeed in lightening the load, we wonder why we're unhappy. This is one of those contradictory aspects of the human condition, and one that's foolish to attempt to resolve. The trick I've found is to believe both things to be true at the same time. Yes, occasionally there's a need to rest and conserve energy. But equally so, there's a need to get back into the arena, and wrestle with something significant. Mojito island , all the time, is a curse, not a blessing. And in fact, it probably is worse, for most people, to have too many stretches of too little to do than the opposite. Tales of workers dropping dead a year into retirement is a common folklore expression of this knowledge. All this to say: don't slice the few, meaningful problems you have at work too thin. The worst injury you can inflict on knowledge workers is leaving them with too little of consequence to contest with. Meaningful problems are the most valuable human motivators. Made-up problems are a blight. Ensure you have not quite enough time and people available to tackle the former lest you start inventing the latter.", "date": "2024-04-11T09:04:00Z", "url": "https://world.hey.com/dhh/enough-problems-to-go-around-c10b887d"}
{"id": "918336ac-b1a3-452c-864d-3bdcc19e5faa", "author": "DHH", "title": "You're not guaranteed a spot on the team", "content": "I've always hated the saying \"we're like family here\" when it comes to work. Because it's obviously not true, and it's usually cynically invoked by management to entice an undue obligation of sacrifice. Implying that you should give it all to The Company -- constantly working weekends, always being available on vacations, and all the rest -- but when the necessities of the business change, you'll realize the obligation was never truly mutual. So far, so agreeable to most people. They usually already have a family. They're not looking to supplant it with a fake corporate version. And they don't need to. Work can and should be friendly, fun, and rewarding without the blood relations. But if work is not a family, what is it then? I think Netflix got it right : it's a professional team. One where colleagues earn a spot by being really good in their given position. But also -- and this is the hard part! -- one where someone may fail to make the cut, if they aren't up to the standards of the team, don't fit in the given position, or simply hasn't been playing well enough for a while. You can't have it both ways. You can't scorn the use of \"we're a family\" and then also expect that colleagues who can't keep up are spared the cut. It's either or, if you're going to have a high-performing team. Think of it this way. There are millions of people playing soccer in the world and having fun. There are probably thousands who play at some level of professionalism. But there are only 11 spots on the starting lineup of Manchester United. You can be very good at soccer, and still not be part of that lineup. Now the natural delusion of every business owner is to think that they're running Manchester United when in fact they're barely hanging on in third division. But the point is actually the same. Even in third division, there's a level of competence that makes someone a good fit. We can't all be the best. But there's room for almost anyone who's half-way decent to play (or work) productively SOMEWHERE. And the reality is that if someone is a fit for third division, they'd have a terrible time on that Manchester United starting lineup. The expectations would be sky high. The gaps in their competency would quickly and painfully be revealed. They'd soon realize they're in the wrong place. Cutting them from the team would be an act of mercy, not cruelty. Note that it's more than fine to give someone who shows promise a chance in a position that seems like a stretch. But after a couple of games, the progress should be apparent. Either you're revealing the fact that they're quickly stepping up to the role or you're revealing the fact that they won't. Both are valuable learnings, but not if you squander the insight, and don't act accordingly. This is perhaps the most important job of the coach or manager. Knowing when to make the cut, and having the strength to do it. There'll always be a million reasons, especially if someone is well-liked, why you should wait longer, be more patient. But to do the job of being in charge well, you have to be decisive in face of incomplete evidence. Not everyone is meant to be Messi or to play on his team. But we wouldn't have much of a sport if his level was the only level. Find your level, find a team that fits with it, and play to the best of your ability. That's the beautiful game.", "date": "2024-04-10T08:41:25Z", "url": "https://world.hey.com/dhh/you-re-not-guaranteed-a-spot-on-the-team-95080248"}
{"id": "d7651bdf-965f-43a8-8b6c-9ac43a3561e5", "author": "DHH", "title": "Le Mans 2024", "content": "This will be my 11th attempt. The first time I showed up on the grid at Le Mans was in 2012 -- some five years after I had first driven a real race car, and even less time since I made participating in the world's greatest endurance race the ultimate goal. But it almost didn't happen this year. See, motorsports relies on a curious mix of money and talent. It's usually not enough just to be good at driving to get a seat in a competitive car. The majority of teams competing, certainly in sports car racing, either are or have been funded by passionate privateers who bring the budget to make racing possible. Even in Formula 1 is this part of the dynamic. I bring some of the money and some of the talent, but never enough to single-handedly make a program worthy of a Le Mans entry happen. I have to team up with other drivers who bring another part of the budget, and a bit more talent, as well as some drivers who just bring their peak talent. Oh, and find a team that preferably has a few sponsors to close the gap. It's always a dance. And this year, it seemed like the dance wasn't going to close. Plenty of conversations, plenty of ideas, but no contract, no signatures. Until suddenly, a few weeks ago, a driver dropped out of their contract, and voila, a seat with Nielsen Racing for the European Le Mans Series and the 24 Hours of Le Mans was available for me to fill. Nice! But it's a weird time in sports car racing. On the one hand, this will be perhaps the most exciting 24 Hours of Le Mans ever, in terms of high-profile manufacturer involvement. We'll see competition between Ferrari, Porsche, Lamborghini, Toyota, Cadillac, BMW, Peugeot, and Alpine this June in France. No wonder the race has been sold out since November. On the other hand, nobody seems to know what the future of the car is going to look like. Is everything going electric? Will AI be driving us all around shortly? Who's going to reap the spoils of this transformation: Software makers in Silicon Valley or battery makers in China? Where does this leave the historic motoring brands of Europe? You'd think this level of uncertainty about the future would have dampened the will among car makers to spend lavishly on big-budget racing programs. And yet we're at an all-time high for both Formula 1 and sportscar racing. It's curious. Not that I'm complaining, mind you. It's rather amazing to be able to participate in such a golden era of motorsport. To be able to show up to the Super Bowl or Wimbledon or World Cup finals of our sport, as an amateur, and compete with the best drivers in the world. What a privilege. Even more so because I know this isn't going to last forever. I was 32 when I first drove at Le Mans. Now I'm 44. Drivers don't get better after forty, that's just a fact. Most have already retired by then, actually. Fernando Alonso, at 42, being the exception that proves the rule. So I keep waiting for my dip to come any minute now. For the lap times to fall off, first a little, then a lot. Or for the incident rate to increase. There's just no fighting nature, it will happen. But perhaps because I don't have that peak talent, I'll be spared a little longer. Be given a few more races at the top of my game, before the inevitable decline comes. I don't say that with any trepidation. I'm at peace with the circle of life, it's array of inevitable declines, and with it's finality. Nobody gets to be their best at almost anything forever, certainly not in the physical realm, and none of us will make it out of alive. If anything, there's a sense of relief in knowing that none of it -- not racing, not programming, not entrepreneurship -- is meant to go on forever. Perhaps this is an easier existential pill to swallow once you've had kids. Seeing my three boys get quicker in their gokarts, whether they'll eventually turn it into car racing or not, tastes like the saying \"when old men plant trees whose shade they know they shall never sit in\". Now we're really off track, but that is perhaps one of the most rewarding aspects of having children. This biologically-infused acceptance of finality. I don't have to live forever, because the human lineage I'm a part of, and that's millions of years old, is going to continue. Whether they'll be racing cars or not. But that brings us back to one of my favorite parts about driving a race car real fast: There's no time for existential deliberation! All your attention must be focused on making the perfect inputs for the next corner, lest you give up a tenth of a second or make a mistake that sends you and the car into the wall. Everything else simply must vanish for your attention to be devoted to the task at hand: Go fast, don't crash. June 14-16 , then. For 24 hours. Zoom, zoom.", "date": "2024-04-03T10:29:14Z", "url": "https://world.hey.com/dhh/le-mans-2024-1f87d732"}
{"id": "f8142e64-765f-4705-830a-98dbc94b877a", "author": "DHH", "title": "Bad Therapy", "content": "This book nails it . What it's like to be a parent with school-age children in America right now. So many kids with a diagnosis of one sort or another, so much monitoring of children's every move, so much anxiety over the most trivial things, like the sugar content of a cupcake. Abigail Shrier ties all these threads together into a damning tapestry of well-cited arguments for why much of modern parenting in America is failing the kids it purports to care for so catastrophically. I simply couldn't put it down. I've read a few parenting books, and I usually have to somewhat dig to find something to take away. But Bad Therapy required no digging. It is unusually dense with eye-opening and deeply resonating take-aways. From its diagnosis to its anecdotes. It's also depressing. That this is what's become of the modern American childhood experience in so many places. The almost fully eroded sense of childhood independence, with its moderate dangers and teaching moments. Replaced with cotton-ball cocoons to keep kids from dealing with even the most minor of setbacks themselves. Lest accusations start flying of how somebody, somewhere OUGHT TO HAVE DONE SOMETHING. It's without a doubt the worst thing about living in America for me at the moment. The hyper-active, hyper-involved parents who have hair-trigger intervention fingers ready to be pulled at the slightest appearance of social discomfort or disharmony. Eager to do calls, follow-ups, and long threads of texting to \"unpack\" whatever happened between so and so in the playground at recess. Placated by administrators and teachers all to eager to assume greater involvement with every living millisecond and millimeter of school life. Combined with the fact that we, me, us are all complicit. All so easily sucked into it all. I hate it. Which is how Shrier's book emerges like such an oasis in the middle of a desert of such arid ideas. From \"gentle parenting\", to social-emotional-learning programs, to trauma-me-this-and-trauma-me-that thinking, it's all seemingly spreading everywhere. So this forceful refutation of the lot of it quenches a deep thirst for opposition. And boy does it deliver! It's delightfully polemic, with pointed and named refutations of the specific intellectuals who are at the center of advancing these bad ideas. It reads like it was written by a writer entirely unafraid of slaughtering the sacred cows of the upper-class zeitgeist. Because it is! In 2020, Shrier wrote Irreversible Damage , about the dramatic surge in transgender identification, and the medical interventions and experiments that have come with it. It was so controversial that it made one of the leading lawyers at the ACLU, Chase Strangio, tweet that \"stopping the circulation of this book and these ideas is 100% a hill I will die on\". Yikes. So to say Shrier has been through the cancellation ringer is an understatement of epic proportions. Her first appearance on Joe Rogan's podcast even prompted a fringe of Spotify employees to protest the company's sponsorship of the podcast. But Shrier made it through. And there is perhaps nothing quite as fortifying as staring down a censorship mob, and then later seeing your testimony confirmed. See the WPATH Files or the NHS' reversal on puberty blockers , as just two examples validating the concerns raised in that book. No wonder Bad Therapy has instantly become a best seller. Regardless of your parenting approach, I think you'll be forced to think long and hard about it after reading Shrier's book. It's all but ensured to push some buttons in almost everyone. When it does, don't quit it, stick with it. The message couldn't be more timely. The mental health statistics on kids and young adults today are horrifying. What American parents have been doing for the last twenty-plus years is so resoundingly not working. All the therapy, the accommodations, the pills, and the interventions have failed to produce a generation of happy, independent kids. It's way over due for thee parents, us parents, to go back to drawing board. There's no way the answer is more of the same. You gotta read it.", "date": "2024-03-31T19:05:58Z", "url": "https://world.hey.com/dhh/bad-therapy-08849dc9"}
{"id": "8d3abc62-b3a3-481f-9cba-ce2938ceed34", "author": "DHH", "title": "Chart the course, set the pace, hold the line", "content": "I break the essential responsibilities of the company executive into three distinct buckets. They are: 1. Chart the course Where are we going? What are we building? Who is it for? Any executive running anything has to know the answer to these questions in order to lead anyone anywhere. If you don't have a clue where you're going, any road can take you there, and running in circles is as good as making progress. This is not viable. That doesn't mean having a five-year plan! Or even a quarterly target! We decide on what features we're going to build for Basecamp and HEY every 6-8 weeks. That's charting the course just in time and at a high resolution. Because if anything, being a \"long-term thinker\" is an invitation to smell your own intellectual exhaust fumes. It's much easier to bullshit from 30,000 ft than it is when imminent decisions stare you in the face. And someone's has to do it! Someone has to say: This is what we're doing. Let's go. 2. Set the pace Not only does work easily expand to fit the time allotted, but our ambitions will shrink along with our declining productivity. The slower you're moving, the less you think you can do, the slower you're moving. The only counter to this is to be ambitious, bold, and impatient. Again, this doesn't mean cracking the whip over a herd of cubicled programmers zombieing their way through yet another death march day on a 12-hour shift. Setting the pace isn't about demanding more hours, it's about demanding more from those hours. It's also about constantly questioning the premise of the work. Why are we doing it this way? Could it be done differently? Are you prepping for contingencies that are too remote to matter? Or are you not spending enough time where it really counts? The only way to tell is by knowing the work. Executives who drift high up in the clouds have a hard time seeing the terrain. You can only get so much information second-hand or from outdated maps. You have to be there to know. So to be bold, you must have insight – or you're just delusional. Credibility is built on pushing for a reach and then actually making it. If you're constantly pushing for the impossible, and none of it happens, you're a clown. Get out of here. 3. Hold the line Quality withers quickly when nobody sweats it. You have to take it personal, to some degree. It has to offend your sensibilities when things are not right, to some degree. Because you need that energy to halt the work and redo what isn't right when you find out. If you let it slide, if you don't sweat, eventually nobody else will. And holding the line on quality isn't just about the customer experience, it's about everything. It's about writing code that'll be a joy to read in three years. It's about giving support staff enough policy leeway to deal with problems (without giving the farm away). It's about making sure none of the writing that's signed by the company makes you cringe. Holding the line also means being willing to pay for it. Always look for a good bargain, when good quality is available at a great price, but never be cheap. You're holding the line so you'll be able to be proud of what you're producing tomorrow, next year, next decade. A culture of quality is built one product and process decision at a time. Do all these three things well, do them consistently, do them when it's hard, do them when it doesn't look like it's working, and regardless of what happens, you'll have done your best with what was there. Whether that's enough for success or sustainability is usually out of your hands anyway. But great execution according to these three responsibilities have a way of finding the gold.", "date": "2024-03-15T17:24:00Z", "url": "https://world.hey.com/dhh/chart-the-course-set-the-pace-hold-the-line-0f3ea916"}
{"id": "5c9ac9ec-eb4a-43a8-9569-29b85b2deb00", "author": "DHH", "title": "Beware the leviathans", "content": "I've been pleading with antitrust authorities around the world to do something about Big Tech for years now. Especially with those awful app store monopolies that have been choking out developers left, right, and center. But now that something finally looks to be happening, I'm suddenly concerned that it might, and that we'll end up wishing that it didn't. It's not because I suddenly have a newfound appreciation for Apple's or Google's right to milk their mobile tollbooths for billions more. Au contraire. My concern is rather that the sovereign leviathans of the world, be it the EU or the US, might not exactly share as many interests with free market advocates as it appears on the surface. Let's start with the Digital Markets Act. That's the main antitrust battering ram hitting the gates of Apple's keep at the moment. And Apple doesn't seem to know what's up, down, or any which way around. They're stumbling from one defiant defeat to the next humiliating flip-flop on policy. It's hard not to be filled with schadenfreude in response. Apple is finally getting a dose of its own infuriating medicine! It's fumbling in the dark trying to comply with vague, ambiguous rules that seem designed for maximum frustration. And it can't seem to get a straight answer from said authorities on exactly what it'll take to be legal. It has to invent a myriad of APIs and policies up front, only then to be told what will be accepted (or not) after the fact. Welcome to our world , Apple. This is exactly what it feels like to be a developer knocking on the door of your app store bureaucracy. Being bandied about from reviewer to reviewer, never certain what it takes to make you happy. Constantly wishing that the next update will just make your bureaucrats go away and leave us alone. But once I've let the dark delight subside, I must return to my principles. The reason developers are so frustrated with the app store monopolies is exactly the absence of clear rules that are consistently and predictably enforced. We want a rule of law where it's obvious what's kosher and what's not. Where everyone is treated the same, regardless of industry, power, or privilege. A lady justice blind to her subjects. In the best case scenario, this awful DMA adventure that Apple is currently struggling through will be a mirror for the company to reflect on its own behavior. And, having felt exactly that sense of intolerable frustration shared by countless developers, they'll use the introspection to reconsider their extractive ways. Yes, that's very much wishful thinking. But I refuse to stop hoping, because if you give up on hope, you're bound to become cynical, and that's a curse worse than any commercial dispossession. But let's return to the biggest potential threat here. Not from Apple, not from Google, but from the sovereign leviathans. The legislatures, the courts, and the rest of the governmental machinery slowly churning their big grinding gears in the US and the EU. The DMA is convoluted and complicated because the EU is trying to have its cake and eat it too. It purports to open markets and ensure competition, but at the same time embrace the power of consolidation by co-opting Apple's (and Google's) reach and gatekeeper privileges. This latter motive is what governments on both sides of the Atlantic have been pursuing for the internet since day one. To bring it under their control. You see this with the scarily authoritarian laws targeting \"misinformation\" and other forms of speech that are spreading in both the new world and the old. You see it in the countless of examples of overt collaboration between the key platforms and government censors. The Twitter Files gave us a depressing look into how officials were circumventing the first amendment in the US, and most of the rest of the world doesn't even have a right to free speech enshrined in their constitution. So laws that seek increasingly draconian penalties for forbidden speech are coming out of the woodwork everywhere. And here's the kicker. These laws need implementation, and no process has proven more effective than deputizing the likes of Apple, Google, Amazon, and other Big Tech platform owners. Making them responsible for carrying out the censorship. Whether that takes the explicit form of official laws and their invocation, like the dystopian financial crackdown on the Canadian trucker protests and their donors, or the threats from officials that pushed Parlor off the internet . Now I know that as soon as we dive into the specifics, like the Canadian trucker protests or Parlor or anything else from those divisive archives, this whole debate turns into a partisan team sport. Whatever lofty principles people hold in the abstract are quickly sacrificed, if there's a chance to score a win against the opposing side. This is when labels fly freely, and suddenly everyone is a nazi or a communist. But whatever side you're on (or whether you take a side at all!), you ought to recognize that the rings of power usually change side every now and then. Every overreach you find justified when its your team wielding the advantage is one you'll rue when it's turned back against you. I think even the most hardcore partisans actually know this, even if they're loathe to admit it. It's why you have a parade of Democrats in the US chasing Trump with every bogus legal claim under the sun while fretting that he'll \"weaponize the courts to pursue his political enemies\", if he wins this November. Pots and kettles, all black. (Yes, again, I recognize that mentioning Trump will completely shut off the frontal lobes of half the audience, if references to Canadian truckers or Parlor didn't do the job already. But the hypocrisy is just too grand to ignore. Regardless of whether you think Trump is a once-in-a-century villain or not.) All this is why reasonable people might well just have second thoughts about whether the US government should ban TikTok. I think there are plenty of valid reasons, most persuasively those on reciprocal trade, but let's not pretend the slippery slope hasn't been proven right repeatedly in the last few years. Emergency powers invoked when honking horns got too much. Misinformation missions expanding to include malinformation too (true information that's unhelpful/damaging to the cause/narrative). Political opponents labeled as traitors and in cahoots with foreign adversaries. I think it's perfectly reasonable to worry how a ban/forced sale of TikTok might pave the way for similar actions against X or Rumble or whoever fails to kick off people saying the wrong words. That's the context in which I worry about what comes next in the fight against Big Tech monopolies. A future where this intolerable concentration of power is not so much disbanded as simply subsumed into the growing arsenal of oppressive powers that are increasingly being collected by Western democracies. All in the name of fighting the ever-expanding list of forbidden words and topics , amongst other boogeymen. I want to see the monopolies of Apple and Google addressed. And I also think the leviathans are our best bet in the short term, but I'm open to the idea that the short term isn't worth selling out our principles for in the long term. That maybe we ought to place our faith in iterative game theory , and the fact that critical platforms do change, albeit rarely and slowly. There's one version of history that holds that it was the Justice Departments case against Microsoft that opened up the tech world to new entrants in the early 2000s. That without their intervention, we'd been doomed to live with the awfulness of IE forever, and Windows would have reigned supreme until the end of our days. But there's another version that sees the inherently disruptive force of the internet, the rise of Firefox, then Chrome, together with Google, Facebook, and the rest of that eras challenges to Microsoft, as happening without the intervention of the leviathan. And that those same forces, and the nature of playing successive rounds of the prisoner's dilemma, is what lead Microsoft to lose the ultimate prize on the next decades: mobile. Usually, I find it relatively easy to navigate such questions and counterfactuals to arrive at a position worth going all-in on. But not this time. This time I'll admit to be equally concerned with whether the EU, to take the DMA specifically, is successful or not. In the end, we might all come to echo Kierkegaard's immortal sense of regret : Tackle Big Tech, and you will regret it. Don't tackle Big Tech, and you will regret that too. Either way, you will regret it. Oy.", "date": "2024-03-15T01:17:38Z", "url": "https://world.hey.com/dhh/beware-the-leviathans-56db3d48"}
{"id": "64f6c9e1-7179-42d8-a85f-b85784e20a64", "author": "DHH", "title": "Developers are on edge", "content": "It's a double whammy of anxiety for developers at the moment. On the one hand, the layoffs are dragging on . The industry has shed more jobs in a shorter period than any time since the dot-com bust over twenty years ago. Seasoned veterans who used to have recruiters banging on their door nonstop can suddenly barely get a callback . And now the threat of AI suddenly got even more urgent and imminent with the launch of Devin . If you zoom out, though, developers are still flying high on tailwinds that took them to the moon over the past decade. Yes, hundreds of thousands of people have lost their jobs in the tech industry, but the preceding hiring bonanza still leaves us with an enormous and wealthy industry. And the wage gains secured during the go-go days are still massive, despite what inflation has eroded over the last few years. Contrast the fortunes of premium programmers in 2024 with their situation from 2014 or 2008, and they're still looking mighty privileged. But humans don't react to absolute status or wealth. All the anxiety or exhilaration is in the delta. Are we moving up or down? Forwards or backwards? And right now, except for a tiny group of gilded AI wizards, most programmers have either seen their prospects stalled or become more precarious. So yesterday's wins are quickly pushed aside by tomorrow's worries. There's some irony in this change of fortune. Programmers, as a group, have prospered tremendously by automating other people's jobs over the past half century. But when it's other people's livelihoods, we naturally have a much easier time seeing the big picture. That the aggregate prosperity of the world improves as productivity goes up. It's a little harder when it's your own profession feeling the pressure. It's hard to tell how real that pressure actually is, though. Okay, the layoffs are indisputable, and the tough hiring environment an inevitable consequence. But the wreckage of the dot-com bust was cleared in a few short years, and then it was back to full steam ahead. And exuberant tech analysts told cabbies in 2017 that self-driving cars were going to put them all out of a job in a hot minute. That still hasn't happened either. That's the trouble with The Future. It's awfully difficult to predict when it'll actually arrive. All we're doing is making bets and taking guesses. My guess would be that just like agriculture went from requiring the participation of 97% of the world's population in the age of subsistence farming to the mere 2% required for our industrial processes today, so too will go the way of the programmer. That is, I do think we've probably seen the high-water mark of the manual programmer. That maybe our industry and employment charts might look like the Tokyo stock market when we look back from the future. Sideways since the 90s . Now that still leaves an enormous industry with plenty of prospects, of course. If anything, AI is likely going to make the tech industry even more integrated in society and thus more valuable. But we just might not need as many human programmers pounding code with their little meat fingers. Just like the aggregate value of the agricultural industry has gone up a lot since the pre-industrial era, even if the number of hands in the field have shrunk to almost nothing. So while it's hard to do, it's useless to worry. The Future is out of your hands and out of your control. No profession has ever successfully resisted automation or redundancy in the face of technological advancement over the long term. Screaming at Devin will only distract you from enjoying the last glorious years of a golden run. C'est la vie!", "date": "2024-03-13T20:37:56Z", "url": "https://world.hey.com/dhh/developers-are-on-edge-4dfcf9c1"}
